<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-11-03 Thu 17:46 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Supervised Machine Learning</title>
<meta name="author" content="Alberto Valdez" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="https://albertovaldez5.gitlab.io/org-template/resources/theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://albertovaldez5.gitlab.io/org-template/resources/theme/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://albertovaldez5.gitlab.io/org-template/resources/theme/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://albertovaldez5.gitlab.io/org-template/resources/theme/js/readtheorg.js"></script>
<link rel="shortcut icon" href="https://albertovaldez5.gitlab.io/org-template/resources/theme/favicon.ico">
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="org-div-home-and-up">
 <a accesskey="h" href=""> UP </a>
 |
 <a accesskey="H" href="https://albertovaldez5.gitlab.io/data-analytics-notes/"> HOME </a>
</div><div id="content" class="content">
<h1 class="title">Supervised Machine Learning
<br />
<span class="subtitle">Automating Decision Making</span>
</h1>
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#machine-learning">1. Machine Learning</a>
<ul>
<li><a href="#supervised-learning">1.1. Supervised Learning</a></li>
<li><a href="#linear-regression">1.2. Linear regression</a></li>
</ul>
</li>
<li><a href="#scikit-learn">2. Scikit-learn</a>
<ul>
<li><a href="#univariate-linear-regression">2.1. Univariate Linear Regression</a></li>
<li><a href="#quantifying-regression">2.2. Quantifying Regression</a></li>
<li><a href="#improving-model-with-tests">2.3. Improving Model with Tests</a></li>
</ul>
</li>
<li><a href="#linear-regression-example">3. Linear Regression Example</a>
<ul>
<li><a href="#load-the-data">3.1. Load the Data</a></li>
<li><a href="#assign-the-data-to-x-and-y">3.2. Assign the data to X and y</a></li>
<li><a href="#plot-the-data">3.3. Plot the data</a></li>
<li><a href="#split-learn-and-test-data">3.4. Split Learn and Test data</a></li>
<li><a href="#create-and-fit-the-model">3.5. Create and Fit the Model</a></li>
<li><a href="#calculate-mse-and-r2">3.6. Calculate MSE and R2</a></li>
<li><a href="#calculate-r2-score">3.7. Calculate R2 Score</a></li>
<li><a href="#conclusion">3.8. Conclusion</a></li>
</ul>
</li>
<li><a href="#logistic-regression">4. Logistic Regression</a>
<ul>
<li><a href="#logistic-regression-in-python">4.1. Logistic regression in python</a></li>
</ul>
</li>
<li><a href="#logistic-regression-example">5. Logistic Regression Example</a>
<ul>
<li><a href="#imports">5.1. Imports</a></li>
<li><a href="#load-the-data">5.2. Load the data</a></li>
<li><a href="#assign-data">5.3. Assign data</a></li>
<li><a href="#init-and-train-the-data">5.4. Init and train the data</a></li>
<li><a href="#make-predictions">5.5. Make predictions</a></li>
<li><a href="#evaluate-model">5.6. Evaluate model</a></li>
<li><a href="#storing-the-model">5.7. Storing the Model</a></li>
<li><a href="#reloading-the-model">5.8. Reloading the Model</a></li>
</ul>
</li>
<li><a href="#confusion-matrix">6. Confusion Matrix</a>
<ul>
<li><a href="#measuring-accuracy">6.1. Measuring Accuracy</a>
<ul>
<li><a href="#accuracy">6.1.1. Accuracy</a></li>
<li><a href="#precision">6.1.2. Precision</a></li>
<li><a href="#sensitivity">6.1.3. Sensitivity</a></li>
</ul>
</li>
<li><a href="#confusion-matrix-in-python">6.2. Confusion Matrix in Python</a></li>
</ul>
</li>
<li><a href="#support-vector-machine">7. Support Vector Machine</a>
<ul>
<li><a href="#svms-in-practice">7.1. SVMs in practice</a></li>
</ul>
</li>
<li><a href="#decision-trees">8. Decision Trees</a>
<ul>
<li><a href="#decision-trees-in-python">8.1. Decision Trees in Python</a></li>
<li><a href="#aggregation">8.2. Aggregation</a></li>
</ul>
</li>
<li><a href="#random-forest-by-hand">9. Random Forest by Hand</a>
<ul>
<li><a href="#org5666fc5">9.1. Imports</a></li>
<li><a href="#create-data">9.2. Create Data</a></li>
<li><a href="#predict">9.3. Predict</a></li>
<li><a href="#bagging">9.4. Bagging</a></li>
<li><a href="#random-forest-pre-built">9.5. Random Forest Pre-built</a></li>
<li><a href="#ada-boost-classifier">9.6. Ada-Boost Classifier</a></li>
</ul>
</li>
<li><a href="#choosing-an-ensemble-model">10. Choosing an Ensemble Model</a>
<ul>
<li><a href="#org545301d">10.1. Imports</a></li>
<li><a href="#loading-the-data">10.2. Loading the Data</a></li>
<li><a href="#creating-a-tester-function">10.3. Creating a Tester function</a></li>
<li><a href="#using-the-function-to-compare-models">10.4. Using the function to compare models</a></li>
</ul>
</li>
<li><a href="#feature-selection-with-random-forest">11. Feature Selection with Random Forest</a>
<ul>
<li><a href="#org44bd283">11.1. Imports</a></li>
<li><a href="#load-data">11.2. Load Data</a></li>
<li><a href="#split-the-data">11.3. Split the Data</a></li>
<li><a href="#creating-a-first-model">11.4. Creating a first Model</a></li>
<li><a href="#using-the-features-attribute">11.5. Using the Features attribute</a></li>
<li><a href="#selecting-features">11.6. Selecting Features</a></li>
<li><a href="#new-model-with-the-selected-features">11.7. New Model with the Selected Features</a></li>
<li><a href="#evaluating-the-new-model">11.8. Evaluating the new Model</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-machine-learning" class="outline-2">
<h2 id="machine-learning"><span class="section-number-2">1.</span> Machine Learning</h2>
<div class="outline-text-2" id="text-machine-learning">
<p>
Machine Learning can be found almost everywhere in the modern tech world.
</p>

<p>
We have different types of analytics: reporting, analysis and prediction. <b>Reporting</b> includes spreadsheets and simple measurements. <b>Analysis</b> includes exploratory analysis, visualization, data transformation, generate new data, etc. Then <b>Prediction</b> includes dealing with data that is not there but we can assume it fits a model, forecasting, enrich datasets, make decisions. We can do two types of prediction, either values (continuous data) or categories (categorical data).
</p>

<p>
Machine Learning algorithms are functions with internal parameters that apply labels to data points. They are able to model our decision making process. The simplest ML model is linear regression, where the parameters use the <code>m</code> and <code>b</code> variables from the line equation.
</p>

<p>
ML is executed with a different approach, as we use many observations to build the algorithm (training data). By using hundreds to millions of observations, we can get a better view on how we can model the behaviour of real-world scenarios.
</p>

<p>
In order to learn, the algorithm receives a lots of inputs with the correct answers as well as the incorrect answers, both labeled appropriately.
</p>

<p>
Supervised learning knows the correct and incorrect answers to the input data. We will have a target variable for the algorithm to optimize on (we know the outcome in advance).
</p>

<p>
Unsupervised learning doesn&rsquo;t have the answers so it will cluster the data in different groups by looking for patterns, so the data scientist must assign labels manually.
</p>

<p>
With reinforcement learning we have a small amount of observations, but we use the outcome from the same model to create more input data. For example, a robot using failed attempts at opening a door and collecting the parameters for those attemps, whenever one is successful, then it will store it and be the first to try in the future.
</p>

<p>
In classification (unsupervised) we look to divide the data into groups. In regression (supervised) we look for a line that sits as close to all observations as possible. They are basically the same problem but with the opposite optimization.
</p>
</div>

<div id="outline-container-supervised-learning" class="outline-3">
<h3 id="supervised-learning"><span class="section-number-3">1.1.</span> Supervised Learning</h3>
<div class="outline-text-3" id="text-supervised-learning">
<p>
The Model-Fit-Predict paradigm is:
</p>

<ol class="org-ol">
<li>Choosing a model</li>
<li>Fit (train)</li>
<li>Predict</li>
</ol>

<p>
This model is stored as a procedure so you can give it unknown data and get a result immediatly.
</p>

<p>
When validating, we use data that the model doesn&rsquo;t know about, so we can verify the validity of the results from the training. Then we assess the model by looking at different measures from the test.
</p>

<p>
The independent variables are features and the dependent variable is called target.
</p>
</div>
</div>

<div id="outline-container-linear-regression" class="outline-3">
<h3 id="linear-regression"><span class="section-number-3">1.2.</span> Linear regression</h3>
<div class="outline-text-3" id="text-linear-regression">
<p>
Linear regression is the simplest model while still being powerful.
</p>

<p>
We use the m and b in the equation of the line as the features for our model.
</p>

<p>
y = B0 + B1x
</p>

<p>
Linear data can have the following trends:
</p>

<ol class="org-ol">
<li>Positive trend</li>
<li>Negative trend</li>
<li>No trend: we have to use a different algorithm</li>
</ol>

<p>
The algorithm measures distances and minimizes different distances between our current line and the observation. In case of many datapoints, the algorithm will optimize for the smaller distance for all the observations.
</p>
</div>
</div>
</div>

<div id="outline-container-scikit-learn" class="outline-2">
<h2 id="scikit-learn"><span class="section-number-2">2.</span> Scikit-learn</h2>
<div class="outline-text-2" id="text-scikit-learn">
<p>
Scikit-learn provides the models for us. We just have to follow the model-fit-predict paradigm.
</p>

<p>
We will start importing a dataset from sklearn.
</p>

<div class="src-name" id="orgd305148">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">import</span> <span style="color: #4EC9B0;">matplotlib.pyplot </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> plt</span>
<span style="color: #569CD6;">import</span> <span style="color: #4EC9B0;">numpy </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> np</span>
<span style="color: #569CD6;">import</span> <span style="color: #4EC9B0;">pandas </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> pd</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> pathlib </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">Path</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.datasets </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> make_regression</span>


<span style="color: #9CDCFE;">X</span>, <span style="color: #9CDCFE;">y</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">make_regression</span>(
    <span style="color: #9CDCFE;">n_samples</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">20</span>,
    <span style="color: #9CDCFE;">n_features</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>,
    <span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">0</span>,
    <span style="color: #9CDCFE;">noise</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">4</span>,
    <span style="color: #9CDCFE;">bias</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">100.0</span>,
)
<span style="color: #9CDCFE;">resources</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">Path</span>(<span style="color: #CE9178;">'../resources'</span>)
</pre>
</div>

<pre class="example" id="org0a0230c">

</pre>

<p>
Plot the data.
</p>

<div class="src-name" id="org13fd5db">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">output</span> <span style="color: #e0e0e0;">=</span> resources <span style="color: #e0e0e0;">/</span> <span style="color: #CE9178;">"dataset1.png"</span>
<span style="color: #9CDCFE;">fig</span>, <span style="color: #9CDCFE;">ax</span> <span style="color: #e0e0e0;">=</span> plt.<span style="color: #ded492;">subplots</span>(<span style="color: #9CDCFE;">figsize</span><span style="color: #e0e0e0;">=</span>(<span style="color: #BBCCAA;">8</span>, <span style="color: #BBCCAA;">5</span>))
ax.<span style="color: #ded492;">scatter</span>(<span style="color: #e0e0e0;">X</span>, y)
fig.<span style="color: #ded492;">savefig</span>(output)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"#+attr_html: :width 500px"</span>)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">f"[[</span><span style="color: #569CD6; background-color: #252525;">{</span><span style="color: #9CDCFE; background-color: #252525;">output</span><span style="color: #569CD6; background-color: #252525;">}</span><span style="color: #CE9178;">]]"</span>)
</pre>
</div>

<div class="org" id="org1ce63ca">

<div id="org6927d2e" class="figure">
<p><img src="../resources/dataset1.png" alt="dataset1.png" width="500px" />
</p>
</div>

</div>

<p>
Now we can import the model from sklearn.
</p>

<div class="src-name" id="org48c0881">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.linear_model </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">LinearRegression</span>

<span style="color: #9CDCFE;">model</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">LinearRegression</span>()
</pre>
</div>

<pre class="example" id="org5388b38">

</pre>

<p>
Then we fit the data (training in one step).
</p>

<div class="src-name" id="orgd9fc294">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python">model.<span style="color: #ded492;">fit</span>(<span style="color: #e0e0e0;">X</span>, y)
<span style="color: #C586C0;">print</span>(model.<span style="color: #9CDCFE;">coef_</span>)
<span style="color: #C586C0;">print</span>(model.<span style="color: #9CDCFE;">intercept_</span>)
</pre>
</div>

<pre class="example" id="org356c94c">
[12.44002424]
101.89622505659258
</pre>

<p>
Then we make a prediction.
</p>

<div class="src-name" id="org5ddeb24">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">predictions</span> <span style="color: #e0e0e0;">=</span> model.<span style="color: #ded492;">predict</span>(<span style="color: #e0e0e0;">X</span>)
<span style="color: #C586C0;">print</span>(predictions)
</pre>
</div>

<pre class="example" id="org61284ee">
[100.01333772 106.87419043 114.0717493   91.27125336  89.73886454
 105.79079485 100.61218004  99.34405128 106.04714178 120.48260494
 113.715348   103.40986521 119.98742273 125.12869172 103.68813057
 107.00408037 111.3635528  129.77299077 107.41789443 123.841079  ]
</pre>

<p>
Then we can compare our prediction with the real data.
</p>

<div class="src-name" id="org8c7ddf1">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">df</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">pd</span>.<span style="color: #4EC9B0;">DataFrame</span>({
    <span style="color: #CE9178;">"predicted"</span>: predictions,
    <span style="color: #CE9178;">"real"</span>: y,
    <span style="color: #CE9178;">"error"</span>: predictions <span style="color: #e0e0e0;">-</span> y
})
<span style="color: #C586C0;">print</span>(df)
</pre>
</div>

<pre class="example" id="orgaabaea5">
     predicted        real     error
0   100.013338   98.019704  1.993634
1   106.874190  108.458654 -1.584464
2   114.071749  107.776544  6.295205
3    91.271253   90.315201  0.956053
4    89.738865   92.047965 -2.309101
5   105.790795  100.144726  5.646069
6   100.612180  104.371286 -3.759106
7    99.344051   95.208967  4.135085
8   106.047142  102.505262  3.541880
9   120.482605  122.119661 -1.637056
10  113.715348  112.287600  1.427748
11  103.409865  107.326140 -3.916275
12  119.987423  121.444549 -1.457126
13  125.128692  125.803460 -0.674768
14  103.688131  104.330672 -0.642542
15  107.004080  112.026181 -5.022101
16  111.363553  106.596614  4.766939
17  129.772991  129.857150 -0.084159
18  107.417894  113.512862 -6.094967
19  123.841079  125.422026 -1.580947
</pre>

<p>
Now we can construct our line for plotting.
</p>

<div class="src-name" id="org6e3aed5">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">output</span> <span style="color: #e0e0e0;">=</span> resources <span style="color: #e0e0e0;">/</span> <span style="color: #CE9178;">"linear2.png"</span>
<span style="color: #9CDCFE;">x_min</span> <span style="color: #e0e0e0;">=</span> <span style="color: #e0e0e0;">X</span>.<span style="color: #ded492;">min</span>()
<span style="color: #9CDCFE;">x_max</span> <span style="color: #e0e0e0;">=</span> <span style="color: #e0e0e0;">X</span>.<span style="color: #ded492;">max</span>()
<span style="color: #9CDCFE;">y_min</span> <span style="color: #e0e0e0;">=</span> model.<span style="color: #ded492;">predict</span>([[x_min]])
<span style="color: #9CDCFE;">y_max</span> <span style="color: #e0e0e0;">=</span> model.<span style="color: #ded492;">predict</span>([[x_max]])

<span style="color: #9CDCFE;">fig</span>, <span style="color: #9CDCFE;">ax</span> <span style="color: #e0e0e0;">=</span> plt.<span style="color: #ded492;">subplots</span>()

ax.<span style="color: #ded492;">scatter</span>(<span style="color: #e0e0e0;">X</span>, y)
ax.<span style="color: #ded492;">plot</span>([x_min, x_max], [y_min, y_max], <span style="color: #9CDCFE;">c</span><span style="color: #e0e0e0;">=</span><span style="color: #CE9178;">'red'</span>)
fig.<span style="color: #ded492;">savefig</span>(output)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"#+attr_html: :width 500px"</span>)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">f"[[</span><span style="color: #569CD6; background-color: #252525;">{</span><span style="color: #9CDCFE; background-color: #252525;">output</span><span style="color: #569CD6; background-color: #252525;">}</span><span style="color: #CE9178;">]]"</span>)
</pre>
</div>

<div class="org" id="org4034f51">

<div id="orgcf7bb6c" class="figure">
<p><img src="../resources/linear2.png" alt="linear2.png" width="500px" />
</p>
</div>

</div>
</div>

<div id="outline-container-univariate-linear-regression" class="outline-3">
<h3 id="univariate-linear-regression"><span class="section-number-3">2.1.</span> Univariate Linear Regression</h3>
<div class="outline-text-3" id="text-univariate-linear-regression">
<p>
If we have many intercepts and features, we will get different coefficients.
</p>

<p>
The residuals are the differences between the true values of y and the predicted values of y. The problem is that it is scale-dependent.
</p>

<p>
We can look at the residuals to see how wrong we are.
</p>

<div class="src-name" id="org62c90ec">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">predictions</span> <span style="color: #e0e0e0;">=</span> model.<span style="color: #ded492;">predict</span>(<span style="color: #e0e0e0;">X</span>)

<span style="color: #9CDCFE;">output</span> <span style="color: #e0e0e0;">=</span> resources <span style="color: #e0e0e0;">/</span> <span style="color: #CE9178;">"residuals.png"</span>

<span style="color: #9CDCFE;">fig</span>, <span style="color: #9CDCFE;">ax</span> <span style="color: #e0e0e0;">=</span> plt.<span style="color: #ded492;">subplots</span>(<span style="color: #9CDCFE;">figsize</span><span style="color: #e0e0e0;">=</span>(<span style="color: #BBCCAA;">8</span>, <span style="color: #BBCCAA;">5</span>))
ax.<span style="color: #ded492;">scatter</span>(predictions, predictions <span style="color: #e0e0e0;">-</span> y)
plt.<span style="color: #ded492;">hlines</span>(<span style="color: #9CDCFE;">y</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">0</span>, <span style="color: #9CDCFE;">xmin</span><span style="color: #e0e0e0;">=</span>predictions.<span style="color: #ded492;">min</span>(), <span style="color: #9CDCFE;">xmax</span><span style="color: #e0e0e0;">=</span>predictions.<span style="color: #ded492;">max</span>())

fig.<span style="color: #ded492;">savefig</span>(output)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"#+attr_html: :width 500px"</span>)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">f"[[</span><span style="color: #569CD6; background-color: #252525;">{</span><span style="color: #9CDCFE; background-color: #252525;">output</span><span style="color: #569CD6; background-color: #252525;">}</span><span style="color: #CE9178;">]]"</span>)
</pre>
</div>

<div class="org" id="org1a6a566">

<div id="org00e2051" class="figure">
<p><img src="../resources/residuals.png" alt="residuals.png" width="500px" />
</p>
</div>

</div>

<p>
We want the residuals to have a nice behaviour, which means that we want values underneath and on top (distributed similarly). This means that the linear regression is not underestimating or underestimating values.
</p>

<p>
The <b>r-squared</b> tells us to which degree we have been able to explain the variance of the target variable using the features. A high <b>r-square</b> means that the model explains the relationship very well.
</p>

<p>
The <b>mean squared error</b> measures the average of the squares of the errors or deviations (scale-dependent).
</p>
</div>
</div>

<div id="outline-container-quantifying-regression" class="outline-3">
<h3 id="quantifying-regression"><span class="section-number-3">2.2.</span> Quantifying Regression</h3>
<div class="outline-text-3" id="text-quantifying-regression">
<p>
We will import our dataset. We can use the metrics library from sklearn to get measurements on our model and build the predictions. Then create a linear regression model.
</p>

<div class="src-name" id="org1141a79">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #579C4C;"># Import dependencies</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.datasets </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> make_regression</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.linear_model </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">LinearRegression</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.metrics </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> mean_squared_error, r2_score</span>

<span style="color: #579C4C;"># Generate some data</span>
<span style="color: #9CDCFE;">X</span>, <span style="color: #9CDCFE;">y</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">make_regression</span>(<span style="color: #9CDCFE;">n_samples</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">20</span>, <span style="color: #9CDCFE;">n_features</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>, <span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">0</span>, <span style="color: #9CDCFE;">noise</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">4</span>, <span style="color: #9CDCFE;">bias</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">100.0</span>)
<span style="color: #9CDCFE;">model</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">LinearRegression</span>()
model.<span style="color: #ded492;">fit</span>(<span style="color: #e0e0e0;">X</span>, y)
<span style="color: #9CDCFE;">predicted</span> <span style="color: #e0e0e0;">=</span> model.<span style="color: #ded492;">predict</span>(<span style="color: #e0e0e0;">X</span>)
</pre>
</div>

<pre class="example" id="orgdc59fca">

</pre>

<p>
Get the r-squared of our regression as well as the mean-squared error. The noisier the data, the lower the r2 value will be, the more samples, the better the r2 will be.
</p>

<div class="src-name" id="org2c01442">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">r2</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">r2_score</span>(y, predicted)
<span style="color: #9CDCFE;">mse</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">mean_squared_error</span>(y, predicted)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"r-squared:"</span>, r2)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"mean-squared error:"</span>, mse)
</pre>
</div>

<pre class="example" id="org8e1ff2a">
r-squared: 0.903603363418708
mean-squared error: 11.933040779746149
</pre>

<p>
If we change to a noisier set, we get different results.
</p>

<div class="src-name" id="org96fb1af">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">X</span>, <span style="color: #9CDCFE;">y</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">make_regression</span>(<span style="color: #9CDCFE;">n_samples</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">20</span>, <span style="color: #9CDCFE;">n_features</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>, <span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">0</span>, <span style="color: #9CDCFE;">noise</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">12</span>, <span style="color: #9CDCFE;">bias</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">100.0</span>)
<span style="color: #9CDCFE;">model</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">LinearRegression</span>()
model.<span style="color: #ded492;">fit</span>(<span style="color: #e0e0e0;">X</span>, y)
<span style="color: #9CDCFE;">predicted</span> <span style="color: #e0e0e0;">=</span> model.<span style="color: #ded492;">predict</span>(<span style="color: #e0e0e0;">X</span>)
<span style="color: #9CDCFE;">r2</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">r2_score</span>(y, predicted)
<span style="color: #9CDCFE;">mse</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">mean_squared_error</span>(y, predicted)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"r-squared:"</span>, r2)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"mean-squared error:"</span>, mse)
</pre>
</div>

<pre class="example" id="org923727d">
r-squared: 0.3348878392803907
mean-squared error: 107.39736701771537
</pre>
</div>
</div>

<div id="outline-container-improving-model-with-tests" class="outline-3">
<h3 id="improving-model-with-tests"><span class="section-number-3">2.3.</span> Improving Model with Tests</h3>
<div class="outline-text-3" id="text-improving-model-with-tests">
<p>
We can split the dataset with sklearn, which results in a 3 to 1 learn-test data.
</p>

<div class="src-name" id="org56bca7f">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.model_selection </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> train_test_split</span>
<span style="color: #9CDCFE;">X_train</span>, <span style="color: #9CDCFE;">X_test</span>, <span style="color: #9CDCFE;">y_train</span>, <span style="color: #9CDCFE;">y_test</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">train_test_split</span>(
    <span style="color: #e0e0e0;">X</span>,
    y,
    <span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">42</span>,
)
<span style="color: #C586C0;">print</span>(y.<span style="color: #9CDCFE;">size</span>)
<span style="color: #C586C0;">print</span>(y_test.<span style="color: #9CDCFE;">size</span>)
<span style="color: #C586C0;">print</span>(y_train.<span style="color: #9CDCFE;">size</span>)
</pre>
</div>

<pre class="example" id="org56e03bb">
20
5
15
</pre>

<p>
We have learned with a different dataset than the testing, one the resulting score is the <b>r-squared</b>.
</p>

<div class="src-name" id="orgd88feec">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python">model.<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_train</span>, y_train)
<span style="color: #9CDCFE;">score</span> <span style="color: #e0e0e0;">=</span> model.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_test</span>, y_test)
<span style="color: #C586C0;">print</span>(score)
</pre>
</div>

<pre class="example" id="org2ca2b39">
0.4351627840398349
</pre>

<p>
If we test the model, and the result is good, we can trust it can keep performing well in new observations.
</p>
</div>
</div>
</div>

<div id="outline-container-linear-regression-example" class="outline-2">
<h2 id="linear-regression-example"><span class="section-number-2">3.</span> Linear Regression Example</h2>
<div class="outline-text-2" id="text-linear-regression-example">
</div>

<div id="outline-container-load-the-data" class="outline-3">
<h3 id="load-the-data"><span class="section-number-3">3.1.</span> Load the Data</h3>
<div class="outline-text-3" id="text-load-the-data">
<div class="src-name" id="org3aa3d2d">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">import</span> <span style="color: #4EC9B0;">matplotlib.pyplot </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> plt</span>
<span style="color: #569CD6;">import</span> <span style="color: #4EC9B0;">numpy </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> np</span>
<span style="color: #569CD6;">import</span> <span style="color: #4EC9B0;">pandas </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> pd</span>

<span style="color: #9CDCFE;">brains</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">pd</span>.<span style="color: #ded492;">read_csv</span>(<span style="color: #CE9178;">'../resources/brain.csv'</span>)
<span style="color: #C586C0;">print</span>(brains.<span style="color: #ded492;">head</span>())
</pre>
</div>

<pre class="example" id="org7fa8fec">
   gender  age  size  weight
0       1    1  4512    1530
1       1    1  3738    1297
2       1    1  4261    1335
3       1    1  3777    1282
4       1    1  4177    1590
</pre>
</div>
</div>

<div id="outline-container-assign-the-data-to-x-and-y" class="outline-3">
<h3 id="assign-the-data-to-x-and-y"><span class="section-number-3">3.2.</span> Assign the data to X and y</h3>
<div class="outline-text-3" id="text-assign-the-data-to-x-and-y">
<div class="src-name" id="org8283c18">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">X</span> <span style="color: #e0e0e0;">=</span> brains[<span style="color: #CE9178;">"weight"</span>].<span style="color: #9CDCFE;">values</span>.<span style="color: #ded492;">reshape</span>(<span style="color: #e0e0e0;">-</span><span style="color: #BBCCAA;">1</span>, <span style="color: #BBCCAA;">1</span>)
<span style="color: #9CDCFE;">y</span> <span style="color: #e0e0e0;">=</span> brains[<span style="color: #CE9178;">"size"</span>].<span style="color: #9CDCFE;">values</span>.<span style="color: #ded492;">reshape</span>(<span style="color: #e0e0e0;">-</span><span style="color: #BBCCAA;">1</span>, <span style="color: #BBCCAA;">1</span>)

<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"Shape: "</span>, <span style="color: #e0e0e0;">X</span>.<span style="color: #9CDCFE;">shape</span>, y.<span style="color: #9CDCFE;">shape</span>)
</pre>
</div>

<pre class="example" id="orgf4ade62">
Shape:  (237, 1) (237, 1)
</pre>
</div>
</div>

<div id="outline-container-plot-the-data" class="outline-3">
<h3 id="plot-the-data"><span class="section-number-3">3.3.</span> Plot the data</h3>
<div class="outline-text-3" id="text-plot-the-data">
<div class="src-name" id="orgd119ef5">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">output</span> <span style="color: #e0e0e0;">=</span> resources <span style="color: #e0e0e0;">/</span> <span style="color: #CE9178;">"brain.png"</span>

<span style="color: #9CDCFE;">fig</span>, <span style="color: #9CDCFE;">ax</span> <span style="color: #e0e0e0;">=</span> plt.<span style="color: #ded492;">subplots</span>(<span style="color: #9CDCFE;">figsize</span><span style="color: #e0e0e0;">=</span>(<span style="color: #BBCCAA;">8</span>, <span style="color: #BBCCAA;">5</span>))
ax.<span style="color: #ded492;">scatter</span>(<span style="color: #e0e0e0;">X</span>, y)
ax.<span style="color: #ded492;">set_xlabel</span>(<span style="color: #CE9178;">"weight of the brain"</span>)
ax.<span style="color: #ded492;">set_ylabel</span>(<span style="color: #CE9178;">"size of the head"</span>)
fig.<span style="color: #ded492;">savefig</span>(output)

<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"#+attr_html: :width 500px"</span>)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">f"[[</span><span style="color: #569CD6; background-color: #252525;">{</span><span style="color: #9CDCFE; background-color: #252525;">output</span><span style="color: #569CD6; background-color: #252525;">}</span><span style="color: #CE9178;">]]"</span>)
</pre>
</div>

<div class="org" id="orgd054dca">

<div id="orgbf909e5" class="figure">
<p><img src="../resources/brain.png" alt="brain.png" width="500px" />
</p>
</div>

</div>
</div>
</div>

<div id="outline-container-split-learn-and-test-data" class="outline-3">
<h3 id="split-learn-and-test-data"><span class="section-number-3">3.4.</span> Split Learn and Test data</h3>
<div class="outline-text-3" id="text-split-learn-and-test-data">
<div class="src-name" id="orgbba707e">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.model_selection </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> train_test_split</span>
<span style="color: #9CDCFE;">X_learn</span>, <span style="color: #9CDCFE;">X_test</span>, <span style="color: #9CDCFE;">y_learn</span>, <span style="color: #9CDCFE;">y_test</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">train_test_split</span>(<span style="color: #e0e0e0;">X</span>, y, <span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">42</span>)
<span style="color: #C586C0;">print</span>(<span style="color: #4EC9B0;">X_learn</span>.<span style="color: #9CDCFE;">size</span>)
<span style="color: #C586C0;">print</span>(<span style="color: #4EC9B0;">X_test</span>.<span style="color: #9CDCFE;">size</span>)
<span style="color: #C586C0;">print</span>(y_learn.<span style="color: #9CDCFE;">size</span>)
<span style="color: #C586C0;">print</span>(y_test.<span style="color: #9CDCFE;">size</span>)
</pre>
</div>

<pre class="example" id="org9465d5e">
177
60
177
60
</pre>
</div>
</div>

<div id="outline-container-create-and-fit-the-model" class="outline-3">
<h3 id="create-and-fit-the-model"><span class="section-number-3">3.5.</span> Create and Fit the Model</h3>
<div class="outline-text-3" id="text-create-and-fit-the-model">
<div class="src-name" id="org1bb6021">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.linear_model </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">LinearRegression</span>

<span style="color: #9CDCFE;">model</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">LinearRegression</span>()
model.<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_learn</span>, y_learn)
<span style="color: #C586C0;">print</span>(model.<span style="color: #9CDCFE;">coef_</span>)
</pre>
</div>

<pre class="example" id="org3ece102">
[[2.35989976]]
</pre>
</div>
</div>

<div id="outline-container-calculate-mse-and-r2" class="outline-3">
<h3 id="calculate-mse-and-r2"><span class="section-number-3">3.6.</span> Calculate MSE and R2</h3>
<div class="outline-text-3" id="text-calculate-mse-and-r2">
<p>
Mean-squared error and r-squared. Using the original dataset, not split in learn-test.
</p>

<div class="src-name" id="orgf4dd29c">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.metrics </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> mean_squared_error, r2_score</span>

<span style="color: #9CDCFE;">predicted</span> <span style="color: #e0e0e0;">=</span> model.<span style="color: #ded492;">predict</span>(<span style="color: #e0e0e0;">X</span>)
<span style="color: #9CDCFE;">r2</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">r2_score</span>(y, predicted)
<span style="color: #9CDCFE;">mse</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">mean_squared_error</span>(y, predicted)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"r-squared:"</span>, r2)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"mean-squared error:"</span>, mse)
</pre>
</div>

<pre class="example" id="orgff54af3">
r-squared: 0.6384806219470258
mean-squared error: 48028.923228939115
</pre>
</div>
</div>

<div id="outline-container-calculate-r2-score" class="outline-3">
<h3 id="calculate-r2-score"><span class="section-number-3">3.7.</span> Calculate R2 Score</h3>
<div class="outline-text-3" id="text-calculate-r2-score">
<p>
Calculate r-squared.
</p>

<div class="src-name" id="org72363d8">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">score</span> <span style="color: #e0e0e0;">=</span> model.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_test</span>, y_test)
<span style="color: #C586C0;">print</span>(score)
</pre>
</div>

<pre class="example" id="org77eacd4">
0.6568088729208812
</pre>
</div>
</div>

<div id="outline-container-conclusion" class="outline-3">
<h3 id="conclusion"><span class="section-number-3">3.8.</span> Conclusion</h3>
<div class="outline-text-3" id="text-conclusion">
<p>
The r-squared is too low so we can&rsquo;t trust this model in the future.
</p>

<div class="src-name" id="orgf2a2b5f">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">y_pred</span> <span style="color: #e0e0e0;">=</span> model.<span style="color: #ded492;">predict</span>(<span style="color: #e0e0e0;">X</span>)
<span style="color: #9CDCFE;">output</span> <span style="color: #e0e0e0;">=</span> resources <span style="color: #e0e0e0;">/</span> <span style="color: #CE9178;">"example2lin.png"</span>
<span style="color: #9CDCFE;">fig</span>, <span style="color: #9CDCFE;">ax</span> <span style="color: #e0e0e0;">=</span> plt.<span style="color: #ded492;">subplots</span>(<span style="color: #9CDCFE;">figsize</span><span style="color: #e0e0e0;">=</span>(<span style="color: #BBCCAA;">8</span>, <span style="color: #BBCCAA;">5</span>))
<span style="color: #579C4C;"># using the model data</span>
ax.<span style="color: #ded492;">scatter</span>(<span style="color: #e0e0e0;">X</span>, y)
ax.<span style="color: #ded492;">plot</span>(<span style="color: #e0e0e0;">X</span>, y_pred, <span style="color: #9CDCFE;">color</span><span style="color: #e0e0e0;">=</span><span style="color: #CE9178;">'red'</span>)
fig.<span style="color: #ded492;">savefig</span>(output)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"#+attr_html: :width 500px"</span>)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">f"[[</span><span style="color: #569CD6; background-color: #252525;">{</span><span style="color: #9CDCFE; background-color: #252525;">output</span><span style="color: #569CD6; background-color: #252525;">}</span><span style="color: #CE9178;">]]"</span>)
</pre>
</div>

<div class="org" id="orgeb41ca2">

<div id="orgeff982c" class="figure">
<p><img src="../resources/example2lin.png" alt="example2lin.png" width="500px" />
</p>
</div>

</div>
</div>
</div>
</div>


<div id="outline-container-logistic-regression" class="outline-2">
<h2 id="logistic-regression"><span class="section-number-2">4.</span> Logistic Regression</h2>
<div class="outline-text-2" id="text-logistic-regression">
<p>
Logistic regression is a classification algorithm used to discrete set of classes or categories (for example Yes/No, True/False, etc).
</p>

<p>
We use it as an activation function, so we set a threshold, whichever passes it will be the positive category and whichever doesn&rsquo;t will be part of the negative category (1 and 0 respectively).
</p>

<p>
We will find the hyperplane that is the farthest away from both groups.
</p>
</div>

<div id="outline-container-logistic-regression-in-python" class="outline-3">
<h3 id="logistic-regression-in-python"><span class="section-number-3">4.1.</span> Logistic regression in python</h3>
<div class="outline-text-3" id="text-logistic-regression-in-python">
<div class="src-name" id="orga642b15">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">import</span> <span style="color: #4EC9B0;">matplotlib.pyplot </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> plt</span>
<span style="color: #569CD6;">import</span> <span style="color: #4EC9B0;">pandas </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> pd</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.datasets </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> make_blobs</span>

<span style="color: #9CDCFE;">X</span>, <span style="color: #9CDCFE;">y</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">make_blobs</span>(<span style="color: #9CDCFE;">centers</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">2</span>, <span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">42</span>)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">f"Labels: </span><span style="color: #569CD6; background-color: #252525;">{</span><span style="color: #9CDCFE; background-color: #252525;">y[:</span><span style="color: #BBCCAA; background-color: #252525;">10</span><span style="color: #9CDCFE; background-color: #252525;">]</span><span style="color: #569CD6; background-color: #252525;">}</span><span style="color: #CE9178;">"</span>)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">f"Data: </span><span style="color: #569CD6; background-color: #252525;">{</span><span style="color: #e0e0e0; background-color: #252525;">X</span><span style="color: #9CDCFE; background-color: #252525;">[:</span><span style="color: #BBCCAA; background-color: #252525;">10</span><span style="color: #9CDCFE; background-color: #252525;">]</span><span style="color: #569CD6; background-color: #252525;">}</span><span style="color: #CE9178;">"</span>)
</pre>
</div>

<pre class="example" id="orgd583ba9">
Labels: [0 1 0 1 1 0 1 1 0 0]
Data: [[-2.98837186  8.82862715]
 [ 5.72293008  3.02697174]
 [-3.05358035  9.12520872]
 [ 5.461939    3.86996267]
 [ 4.86733877  3.28031244]
 [-2.14780202 10.55232269]
 [ 4.91656964  2.80035293]
 [ 3.08921541  2.04173266]
 [-2.90130578  7.55077118]
 [-3.34841515  8.70507375]]
</pre>

<div class="src-name" id="orgc0b11cd">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">output</span> <span style="color: #e0e0e0;">=</span> resources <span style="color: #e0e0e0;">/</span> <span style="color: #CE9178;">"logistic1.png"</span>

<span style="color: #9CDCFE;">fig</span>, <span style="color: #9CDCFE;">ax</span> <span style="color: #e0e0e0;">=</span> plt.<span style="color: #ded492;">subplots</span>(<span style="color: #9CDCFE;">figsize</span><span style="color: #e0e0e0;">=</span>(<span style="color: #BBCCAA;">8</span>, <span style="color: #BBCCAA;">5</span>))
ax.<span style="color: #ded492;">scatter</span>(<span style="color: #e0e0e0;">X</span>[:, <span style="color: #BBCCAA;">0</span>], <span style="color: #e0e0e0;">X</span>[:, <span style="color: #BBCCAA;">1</span>], <span style="color: #9CDCFE;">c</span><span style="color: #e0e0e0;">=</span>y)
fig.<span style="color: #ded492;">savefig</span>(output)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"#+attr_html: :width 500px"</span>)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">f"[[</span><span style="color: #569CD6; background-color: #252525;">{</span><span style="color: #9CDCFE; background-color: #252525;">output</span><span style="color: #569CD6; background-color: #252525;">}</span><span style="color: #CE9178;">]]"</span>)
</pre>
</div>

<div class="org" id="org904f151">

<div id="org0c638ba" class="figure">
<p><img src="../resources/logistic1.png" alt="logistic1.png" width="500px" />
</p>
</div>

</div>

<p>
We split the data.
</p>

<div class="src-name" id="org9d65021">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.model_selection </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> train_test_split</span>
<span style="color: #9CDCFE;">X_train</span>, <span style="color: #9CDCFE;">X_test</span>, <span style="color: #9CDCFE;">y_train</span>, <span style="color: #9CDCFE;">y_test</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">train_test_split</span>(
    <span style="color: #e0e0e0;">X</span>,
    y,
    <span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>,
    <span style="color: #9CDCFE;">stratify</span><span style="color: #e0e0e0;">=</span>y
)
<span style="color: #C586C0;">print</span>(<span style="color: #4EC9B0;">X_train</span>.<span style="color: #9CDCFE;">size</span>)
<span style="color: #C586C0;">print</span>(<span style="color: #4EC9B0;">X_test</span>.<span style="color: #9CDCFE;">size</span>)
</pre>
</div>

<pre class="example" id="org1f526b9">
150
50
</pre>

<p>
We create a classifier with the logistic regression model.
</p>

<div class="src-name" id="org5ee6804">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.linear_model </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">LogisticRegression</span>

<span style="color: #9CDCFE;">classifier</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">LogisticRegression</span>(
    <span style="color: #9CDCFE;">solver</span><span style="color: #e0e0e0;">=</span><span style="color: #CE9178;">'lbfgs'</span>,
    <span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>
)
classifier.<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_train</span>, y_train)
<span style="color: #9CDCFE;">score</span> <span style="color: #e0e0e0;">=</span> classifier.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_test</span>, y_test)
<span style="color: #C586C0;">print</span>(score)
</pre>
</div>

<pre class="example" id="org44f0044">

</pre>

<p>
Instead of building a line that can be represented a line with an intercept and a slope, we use it as a part of a logistic activation function. It finds a space between the classes and allows us to separate them.
</p>

<p>
If we introduce new data we can get a classification for it.
</p>

<div class="src-name" id="org216f0e5">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">new_data</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">np</span>.<span style="color: #ded492;">array</span>([[<span style="color: #BBCCAA;">2</span>, <span style="color: #BBCCAA;">6</span>]])
<span style="color: #9CDCFE;">output</span> <span style="color: #e0e0e0;">=</span> resources <span style="color: #e0e0e0;">/</span> <span style="color: #CE9178;">"logistic2.png"</span>

<span style="color: #9CDCFE;">fig</span>, <span style="color: #9CDCFE;">ax</span> <span style="color: #e0e0e0;">=</span> plt.<span style="color: #ded492;">subplots</span>(<span style="color: #9CDCFE;">figsize</span><span style="color: #e0e0e0;">=</span>(<span style="color: #BBCCAA;">8</span>, <span style="color: #BBCCAA;">5</span>))
ax.<span style="color: #ded492;">scatter</span>(<span style="color: #e0e0e0;">X</span>[:, <span style="color: #BBCCAA;">0</span>], <span style="color: #e0e0e0;">X</span>[:, <span style="color: #BBCCAA;">1</span>], <span style="color: #9CDCFE;">c</span><span style="color: #e0e0e0;">=</span>y)
ax.<span style="color: #ded492;">scatter</span>(new_data[<span style="color: #BBCCAA;">0</span>, <span style="color: #BBCCAA;">0</span>], new_data[<span style="color: #BBCCAA;">0</span>, <span style="color: #BBCCAA;">1</span>], <span style="color: #9CDCFE;">c</span><span style="color: #e0e0e0;">=</span><span style="color: #CE9178;">"r"</span>, <span style="color: #9CDCFE;">marker</span><span style="color: #e0e0e0;">=</span><span style="color: #CE9178;">"o"</span>, <span style="color: #9CDCFE;">s</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">100</span>)
fig.<span style="color: #ded492;">savefig</span>(output)

<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"#+attr_html: :width 500px"</span>)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">f"[[</span><span style="color: #569CD6; background-color: #252525;">{</span><span style="color: #9CDCFE; background-color: #252525;">output</span><span style="color: #569CD6; background-color: #252525;">}</span><span style="color: #CE9178;">]]"</span>)
</pre>
</div>

<div class="org" id="orga034da9">

<div id="org2c65fc5" class="figure">
<p><img src="../resources/logistic2.png" alt="logistic2.png" width="500px" />
</p>
</div>

</div>

<p>
So if we evaluate the new observation, we would expect to fit one of the classes.
</p>

<div class="src-name" id="org9476247">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">predictions</span> <span style="color: #e0e0e0;">=</span> classifier.<span style="color: #ded492;">predict</span>(new_data)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">f"The new point was classified as: </span><span style="color: #569CD6; background-color: #252525;">{</span><span style="color: #9CDCFE; background-color: #252525;">predictions</span><span style="color: #569CD6; background-color: #252525;">}</span><span style="color: #CE9178;">"</span>)
</pre>
</div>

<pre class="example" id="org9046837">
The new point was classified as: [1]
</pre>
</div>
</div>
</div>

<div id="outline-container-logistic-regression-example" class="outline-2">
<h2 id="logistic-regression-example"><span class="section-number-2">5.</span> Logistic Regression Example</h2>
<div class="outline-text-2" id="text-logistic-regression-example">
</div>

<div id="outline-container-imports" class="outline-3">
<h3 id="imports"><span class="section-number-3">5.1.</span> Imports</h3>
<div class="outline-text-3" id="text-imports">
<div class="src-name" id="org29d6262">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.linear_model </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">LogisticRegression</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.model_selection </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> train_test_split</span>

<span style="color: #569CD6;">import</span> <span style="color: #4EC9B0;">matplotlib.pyplot </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> plt</span>
<span style="color: #569CD6;">import</span> <span style="color: #4EC9B0;">pandas </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> pd</span>
<span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> os</span>

<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> joblib </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> dump, load</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-load-the-data" class="outline-3">
<h3 id="load-the-data"><span class="section-number-3">5.2.</span> Load the data</h3>
<div class="outline-text-3" id="text-load-the-data">
<div class="src-name" id="org39e9169">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">notes</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">pd</span>.<span style="color: #ded492;">read_csv</span>(<span style="color: #CE9178;">'../resources/data_banknote_authentication.csv'</span>, <span style="color: #9CDCFE;">header</span><span style="color: #e0e0e0;">=</span><span style="color: #569CD6;">None</span>, <span style="color: #9CDCFE;">names</span><span style="color: #e0e0e0;">=</span>[<span style="color: #CE9178;">'variance'</span>,<span style="color: #CE9178;">'skewness'</span>,<span style="color: #CE9178;">'curtosis'</span>, <span style="color: #CE9178;">'entropy'</span>, <span style="color: #CE9178;">'class'</span>])
<span style="color: #C586C0;">print</span>(notes.<span style="color: #ded492;">head</span>())
</pre>
</div>

<pre class="example" id="org3338163">
   variance  skewness  curtosis  entropy  class
0   3.62160    8.6661   -2.8073 -0.44699      0
1   4.54590    8.1674   -2.4586 -1.46210      0
2   3.86600   -2.6383    1.9242  0.10645      0
3   3.45660    9.5228   -4.0112 -3.59440      0
4   0.32924   -4.4552    4.5718 -0.98880      0
</pre>
</div>
</div>

<div id="outline-container-assign-data" class="outline-3">
<h3 id="assign-data"><span class="section-number-3">5.3.</span> Assign data</h3>
<div class="outline-text-3" id="text-assign-data">
<div class="src-name" id="orgc14f91f">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">y</span> <span style="color: #e0e0e0;">=</span> notes[<span style="color: #CE9178;">"class"</span>]
<span style="color: #9CDCFE;">X</span> <span style="color: #e0e0e0;">=</span> notes.<span style="color: #ded492;">drop</span>(<span style="color: #9CDCFE;">columns</span><span style="color: #e0e0e0;">=</span><span style="color: #CE9178;">"class"</span>)
<span style="color: #9CDCFE;">X_train</span>, <span style="color: #9CDCFE;">X_test</span>, <span style="color: #9CDCFE;">y_train</span>, <span style="color: #9CDCFE;">y_test</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">train_test_split</span>(
    <span style="color: #e0e0e0;">X</span>,
    y,
    <span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>,
    <span style="color: #9CDCFE;">stratify</span><span style="color: #e0e0e0;">=</span>y
)
<span style="color: #C586C0;">print</span>(<span style="color: #4EC9B0;">X_train</span>.<span style="color: #9CDCFE;">shape</span>, <span style="color: #4EC9B0;">X_test</span>.<span style="color: #9CDCFE;">shape</span>)
</pre>
</div>

<pre class="example" id="org32f3e0b">
(1029, 4) (343, 4)
</pre>
</div>
</div>

<div id="outline-container-init-and-train-the-data" class="outline-3">
<h3 id="init-and-train-the-data"><span class="section-number-3">5.4.</span> Init and train the data</h3>
<div class="outline-text-3" id="text-init-and-train-the-data">
<div class="src-name" id="orga30898a">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">classifier</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">LogisticRegression</span>(
    <span style="color: #9CDCFE;">solver</span><span style="color: #e0e0e0;">=</span><span style="color: #CE9178;">'lbfgs'</span>,
    <span style="color: #9CDCFE;">max_iter</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">200</span>, <span style="color: #579C4C;"># upper limit of num of iter solver</span>
    <span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>
)
classifier.<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_train</span>, y_train)
<span style="color: #C586C0;">print</span>(classifier)
</pre>
</div>

<pre class="example" id="org8b708be">
LogisticRegression(max_iter=200, random_state=1)
</pre>
</div>
</div>

<div id="outline-container-make-predictions" class="outline-3">
<h3 id="make-predictions"><span class="section-number-3">5.5.</span> Make predictions</h3>
<div class="outline-text-3" id="text-make-predictions">
<div class="src-name" id="org3f338a9">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">y_pred</span> <span style="color: #e0e0e0;">=</span> classifier.<span style="color: #ded492;">predict</span>(<span style="color: #4EC9B0;">X_test</span>)
<span style="color: #9CDCFE;">results</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">pd</span>.<span style="color: #4EC9B0;">DataFrame</span>({<span style="color: #CE9178;">"Prediction"</span>: y_pred, <span style="color: #CE9178;">"Actual"</span>: y_test}).<span style="color: #ded492;">reset_index</span>(<span style="color: #9CDCFE;">drop</span><span style="color: #e0e0e0;">=</span><span style="color: #569CD6;">True</span>)
<span style="color: #C586C0;">print</span>(<span style="color: #4EC9B0;">results</span>.<span style="color: #ded492;">head</span>())
</pre>
</div>

<pre class="example" id="orga52a45d">
   Prediction  Actual
0           0       0
1           0       0
2           1       1
3           0       0
4           0       0
</pre>
</div>
</div>

<div id="outline-container-evaluate-model" class="outline-3">
<h3 id="evaluate-model"><span class="section-number-3">5.6.</span> Evaluate model</h3>
<div class="outline-text-3" id="text-evaluate-model">
<div class="src-name" id="org72841e2">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">train_score</span> <span style="color: #e0e0e0;">=</span> classifier.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_train</span>, y_train)
<span style="color: #9CDCFE;">test_score</span> <span style="color: #e0e0e0;">=</span> classifier.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_test</span>, y_test)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"train score:"</span>, train_score)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"test score:"</span>, test_score)
</pre>
</div>

<pre class="example" id="org6abc4f8">
train score: 0.9883381924198251
test score: 0.9941690962099126
</pre>
</div>
</div>

<div id="outline-container-storing-the-model" class="outline-3">
<h3 id="storing-the-model"><span class="section-number-3">5.7.</span> Storing the Model</h3>
<div class="outline-text-3" id="text-storing-the-model">
<p>
We can save the trained model for later.
</p>

<div class="src-name" id="org98c7f5d">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #ded492;">dump</span>(classifier, <span style="color: #CE9178;">'model.joblib'</span>)
</pre>
</div>
</div>
</div>

<div id="outline-container-reloading-the-model" class="outline-3">
<h3 id="reloading-the-model"><span class="section-number-3">5.8.</span> Reloading the Model</h3>
<div class="outline-text-3" id="text-reloading-the-model">
<p>
If we reload the model, we don&rsquo;t have to train it, we shouldn&rsquo;t. So we load new data and create a prediction with the model.
</p>

<div class="src-name" id="org863f475">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">model2</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">load</span>(<span style="color: #CE9178;">'model.joblib'</span>)
<span style="color: #9CDCFE;">new_data</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">pd</span>.<span style="color: #4EC9B0;">DataFrame</span>(
    {
        <span style="color: #CE9178;">"variance"</span>: <span style="color: #BBCCAA;">3</span>,
        <span style="color: #CE9178;">"skewness"</span>: <span style="color: #BBCCAA;">2</span>,
        <span style="color: #CE9178;">"curtosis"</span>: <span style="color: #BBCCAA;">1</span>,
        <span style="color: #CE9178;">"entropy"</span>: <span style="color: #BBCCAA;">0</span>
    },
    <span style="color: #9CDCFE;">index</span> <span style="color: #e0e0e0;">=</span> [<span style="color: #BBCCAA;">0</span>]
)
<span style="color: #9CDCFE;">predictions</span> <span style="color: #e0e0e0;">=</span> model2.<span style="color: #ded492;">predict</span>(new_data)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">f"The new point was classified as: </span><span style="color: #569CD6; background-color: #252525;">{</span><span style="color: #9CDCFE; background-color: #252525;">predictions</span><span style="color: #569CD6; background-color: #252525;">}</span><span style="color: #CE9178;">"</span>)
</pre>
</div>

<pre class="example" id="org77393dc">
The new point was classified as: [0]
</pre>
</div>
</div>
</div>


<div id="outline-container-confusion-matrix" class="outline-2">
<h2 id="confusion-matrix"><span class="section-number-2">6.</span> Confusion Matrix</h2>
<div class="outline-text-2" id="text-confusion-matrix">
</div>

<div id="outline-container-measuring-accuracy" class="outline-3">
<h3 id="measuring-accuracy"><span class="section-number-3">6.1.</span> Measuring Accuracy</h3>
<div class="outline-text-3" id="text-measuring-accuracy">
<p>
The confusion Matrix will tell us how many times our model was able to predict correct observations, this gives us other important measurements like <b>sensitivity</b> that we need to consider while evaluating the models.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">Predicted True</td>
<td class="org-left">Predicted False</td>
</tr>

<tr>
<td class="org-left">Actually True</td>
<td class="org-left">128 (True Positives)</td>
<td class="org-left">5 (False Negatives)</td>
</tr>

<tr>
<td class="org-left">Actually False</td>
<td class="org-left">6 (False Positives)</td>
<td class="org-left">111 (True Negatives)</td>
</tr>
</tbody>
</table>

<p>
We build confusion matrices on <b>test</b> data.
</p>

<ol class="org-ol">
<li>True or False means that our model and the actual result is what we expected or not.</li>
<li>Positive and Negative refers to the category that the model gave out</li>
</ol>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">Predicted True</th>
<th scope="col" class="org-left">Predicted False</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Actually True</td>
<td class="org-left">TRUE POSITIVE</td>
<td class="org-left">FALSE NEGATIVE</td>
</tr>

<tr>
<td class="org-left">Actually False</td>
<td class="org-left">FALSE POSITIVE</td>
<td class="org-left">TRUE NEGATIVE</td>
</tr>
</tbody>
</table>
</div>

<div id="outline-container-accuracy" class="outline-4">
<h4 id="accuracy"><span class="section-number-4">6.1.1.</span> Accuracy</h4>
<div class="outline-text-4" id="text-accuracy">
<p>
Accuracy is the number of correct predictions against the total number of predictions.
</p>

\begin{equation}
Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}
</div>
</div>

<div id="outline-container-precision" class="outline-4">
<h4 id="precision"><span class="section-number-4">6.1.2.</span> Precision</h4>
<div class="outline-text-4" id="text-precision">
<p>
Precision is the measure of how likely is that the prediction is actually true. It tells us the percentage of positive predictions that are correct, how precise a positive prediction is.
</p>

\begin{equation}
Precision = \frac{TP}{TP + FP}
\end{equation}
</div>
</div>

<div id="outline-container-sensitivity" class="outline-4">
<h4 id="sensitivity"><span class="section-number-4">6.1.3.</span> Sensitivity</h4>
<div class="outline-text-4" id="text-sensitivity">
<p>
Sensitivity is the capability of the model of understanding to which category the data corresponds.
</p>

\begin{equation}
Sensitivity = \frac{TP}{TP + FN}
\end{equation}
</div>
</div>
</div>

<div id="outline-container-confusion-matrix-in-python" class="outline-3">
<h3 id="confusion-matrix-in-python"><span class="section-number-3">6.2.</span> Confusion Matrix in Python</h3>
<div class="outline-text-3" id="text-confusion-matrix-in-python">
<div class="src-name" id="org4a2f2c2">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.metrics </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> confusion_matrix, classification_report</span>

<span style="color: #9CDCFE;">matrix</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">confusion_matrix</span>(y_test, y_pred)
<span style="color: #9CDCFE;">true_positive</span> <span style="color: #e0e0e0;">=</span> <span style="color: #9CDCFE;">tp</span> <span style="color: #e0e0e0;">=</span> matrix[<span style="color: #BBCCAA;">0</span>][<span style="color: #BBCCAA;">0</span>]
<span style="color: #9CDCFE;">false_negative</span> <span style="color: #e0e0e0;">=</span> <span style="color: #9CDCFE;">fn</span> <span style="color: #e0e0e0;">=</span> matrix[<span style="color: #BBCCAA;">0</span>][<span style="color: #BBCCAA;">1</span>]
<span style="color: #9CDCFE;">false_positive</span> <span style="color: #e0e0e0;">=</span> <span style="color: #9CDCFE;">fp</span> <span style="color: #e0e0e0;">=</span> matrix[<span style="color: #BBCCAA;">1</span>][<span style="color: #BBCCAA;">0</span>]
<span style="color: #9CDCFE;">true_negative</span> <span style="color: #e0e0e0;">=</span> <span style="color: #9CDCFE;">tn</span> <span style="color: #e0e0e0;">=</span> matrix[<span style="color: #BBCCAA;">1</span>][<span style="color: #BBCCAA;">1</span>]
<span style="color: #C586C0;">print</span>(matrix)
</pre>
</div>

<pre class="example" id="orgfe28b3e">
[[189   1]
 [  1 152]]
</pre>

<p>
Then we can calculate the accuracy and sensitivity.
</p>

<div class="src-name" id="org26b59dc">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"accuracy:"</span>, (tp <span style="color: #e0e0e0;">+</span> tn) <span style="color: #e0e0e0;">/</span> (tp <span style="color: #e0e0e0;">+</span> fn <span style="color: #e0e0e0;">+</span> tn <span style="color: #e0e0e0;">+</span> fp))
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"sensitivity:"</span>, tp <span style="color: #e0e0e0;">/</span> (tp <span style="color: #e0e0e0;">+</span> fp))
</pre>
</div>

<pre class="example" id="orga03e183">
accuracy: 0.9941690962099126
sensitivity: 0.9947368421052631
</pre>

<p>
Then we can generate a classification report.
</p>

<div class="src-name" id="org123fda3">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">report</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">classification_report</span>(y_test, y_pred)
<span style="color: #C586C0;">print</span>(report)
</pre>
</div>

<pre class="example" id="orga59340c">
              precision    recall  f1-score   support

           0       0.99      0.99      0.99       190
           1       0.99      0.99      0.99       153

    accuracy                           0.99       343
   macro avg       0.99      0.99      0.99       343
weighted avg       0.99      0.99      0.99       343
</pre>
</div>
</div>
</div>

<div id="outline-container-support-vector-machine" class="outline-2">
<h2 id="support-vector-machine"><span class="section-number-2">7.</span> Support Vector Machine</h2>
<div class="outline-text-2" id="text-support-vector-machine">
<p>
Support Vector Machines (SVMs) are binary classifiers. It is similar to logistic regression, however, the goal of SVM is to find a line that separates the data into two classes. SVM draws a line at the edge of each class, and attempts to maximize the distance between them. It does so by separating the data points with the largest possible margins.
</p>

<p>
The hyperplanes need the widest equidistant margins possible. This improves classification predictions. The width of the margin is considered the margin of separation.
</p>

<p>
Support vectors are the data points closest to the hyperplane. They serve as decision boundaries for classification.
</p>

<p>
However, when there is an outlier, we can use soft margins to accomodate them, as they allow SVMs to make allowances.
</p>

<p>
In a 3D plane, the hyperplane would need to consider the another dimension to separate the both classes.
</p>
</div>

<div id="outline-container-svms-in-practice" class="outline-3">
<h3 id="svms-in-practice"><span class="section-number-3">7.1.</span> SVMs in practice</h3>
<div class="outline-text-3" id="text-svms-in-practice">
<p>
We are going to start with a model that has already been scaled.
</p>

<div class="src-name" id="org57ccbb9">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">data</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">Path</span>(<span style="color: #CE9178;">'../resources/loans.csv'</span>)
<span style="color: #9CDCFE;">df</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">pd</span>.<span style="color: #ded492;">read_csv</span>(data)
<span style="color: #C586C0;">print</span>(df.<span style="color: #ded492;">head</span>())
</pre>
</div>

<pre class="example" id="orgec8ebe5">
     assets  liabilities  ...  mortgage   status
0  0.210859     0.452865  ...  0.302682     deny
1  0.395018     0.661153  ...  0.502831  approve
2  0.291186     0.593432  ...  0.315574  approve
3  0.458640     0.576156  ...  0.394891  approve
4  0.463470     0.292414  ...  0.566605  approve

[5 rows x 6 columns]
</pre>

<p>
Then we select the data and split it for training.
</p>

<div class="src-name" id="org6163870">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">y</span> <span style="color: #e0e0e0;">=</span> df[<span style="color: #CE9178;">"status"</span>]
<span style="color: #9CDCFE;">X</span> <span style="color: #e0e0e0;">=</span> df.<span style="color: #ded492;">drop</span>(<span style="color: #9CDCFE;">columns</span><span style="color: #e0e0e0;">=</span><span style="color: #CE9178;">"status"</span>)

<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.model_selection </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> train_test_split</span>

<span style="color: #9CDCFE;">X_train</span>, <span style="color: #9CDCFE;">X_test</span>, <span style="color: #9CDCFE;">y_train</span>, <span style="color: #9CDCFE;">y_test</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">train_test_split</span>(<span style="color: #e0e0e0;">X</span>, y, <span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>, <span style="color: #9CDCFE;">stratify</span><span style="color: #e0e0e0;">=</span>y)
<span style="color: #C586C0;">print</span>(<span style="color: #4EC9B0;">X_test</span>.<span style="color: #9CDCFE;">shape</span>)
<span style="color: #C586C0;">print</span>(<span style="color: #4EC9B0;">X_train</span>.<span style="color: #9CDCFE;">shape</span>)
</pre>
</div>

<pre class="example" id="org2ed68c9">
(25, 5)
(75, 5)
</pre>

<p>
Then we import the model from sklearn and we train it with fit.
</p>

<div class="src-name" id="orge7b67aa">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.svm </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #e0e0e0;">SVC</span>
<span style="color: #9CDCFE;">model</span> <span style="color: #e0e0e0;">=</span> <span style="color: #e0e0e0;">SVC</span>(<span style="color: #9CDCFE;">kernel</span><span style="color: #e0e0e0;">=</span><span style="color: #CE9178;">'linear'</span>)

model.<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_train</span>, y_train)
</pre>
</div>

<pre class="example" id="orga23885e">

</pre>

<p>
Finally we create the predictions.
</p>

<div class="src-name" id="org9ba46dd">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">y_pred</span> <span style="color: #e0e0e0;">=</span> model.<span style="color: #ded492;">predict</span>(<span style="color: #4EC9B0;">X_test</span>)
<span style="color: #9CDCFE;">results</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">pd</span>.<span style="color: #4EC9B0;">DataFrame</span>({
    <span style="color: #CE9178;">"Prediction"</span>: y_pred,
    <span style="color: #CE9178;">"Actual"</span>: y_test
}).<span style="color: #ded492;">reset_index</span>(<span style="color: #9CDCFE;">drop</span><span style="color: #e0e0e0;">=</span><span style="color: #569CD6;">True</span>)
<span style="color: #C586C0;">print</span>(<span style="color: #4EC9B0;">results</span>.<span style="color: #ded492;">head</span>())
</pre>
</div>

<pre class="example" id="org0f1d184">
  Prediction   Actual
0    approve     deny
1       deny  approve
2       deny     deny
3    approve     deny
4       deny     deny
</pre>

<p>
Then we get the accuracy score and generate a prediction matrix.
</p>

<div class="src-name" id="orga221b82">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.metrics </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> accuracy_score</span>

<span style="color: #ded492;">accuracy_score</span>(y_test, y_pred)

<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.metrics </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> confusion_matrix</span>
<span style="color: #ded492;">confusion_matrix</span>(y_test, y_pred)

<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.metrics </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> classification_report</span>
<span style="color: #C586C0;">print</span>(<span style="color: #ded492;">classification_report</span>(y_test, y_pred))
</pre>
</div>

<pre class="example" id="org5128482">
              precision    recall  f1-score   support

     approve       0.58      0.58      0.58        12
        deny       0.62      0.62      0.62        13

    accuracy                           0.60        25
   macro avg       0.60      0.60      0.60        25
weighted avg       0.60      0.60      0.60        25
</pre>

<p>
The workflow of a SVM is very similar to a logistic regression:
</p>

<ol class="org-ol">
<li>Select the data (independent and dependent).</li>
<li>Split the data for training.</li>
<li>Create and train the model.</li>
<li>Create predictions.</li>
<li>Validate the model.</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-decision-trees" class="outline-2">
<h2 id="decision-trees"><span class="section-number-2">8.</span> Decision Trees</h2>
<div class="outline-text-2" id="text-decision-trees">
<p>
A decision tree is an algorithm that builds a collection of if-then-else clasues that allow us to find the feature values that are more likely to correspond to a given category, so they can work with multiple categories.
</p>

<p>
Decision trees can become deep and complex depending on the number of questions that have to be answered. Deep and complex trees tend to overfit the data and don&rsquo;t generalize well.
</p>
</div>

<div id="outline-container-decision-trees-in-python" class="outline-3">
<h3 id="decision-trees-in-python"><span class="section-number-3">8.1.</span> Decision Trees in Python</h3>
<div class="outline-text-3" id="text-decision-trees-in-python">
<p>
We can visualize a decision tree with <code>graphviz</code> and <code>pydotplus</code>.
</p>

<div class="src-name" id="org9e031dd">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> tree</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.datasets </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> load_iris</span>
<span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> graphviz</span>
<span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> pydotplus</span>

<span style="color: #9CDCFE;">iris</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">load_iris</span>()
<span style="color: #9CDCFE;">clf</span> <span style="color: #e0e0e0;">=</span> tree.<span style="color: #4EC9B0;">DecisionTreeClassifier</span>()
<span style="color: #9CDCFE;">clf</span> <span style="color: #e0e0e0;">=</span> clf.<span style="color: #ded492;">fit</span>(iris.<span style="color: #9CDCFE;">data</span>, iris.<span style="color: #9CDCFE;">target</span>)

<span style="color: #9CDCFE;">score</span> <span style="color: #e0e0e0;">=</span> clf.<span style="color: #ded492;">score</span>(iris.<span style="color: #9CDCFE;">data</span>, iris.<span style="color: #9CDCFE;">target</span>)
<span style="color: #C586C0;">print</span>(score)
</pre>
</div>

<pre class="example" id="orgb6e57ee">
1.0
</pre>

<div class="src-name" id="org5ec265b">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">file</span> <span style="color: #e0e0e0;">=</span> <span style="color: #CE9178;">'../resources/tree1.png'</span>
<span style="color: #9CDCFE;">dot_data</span> <span style="color: #e0e0e0;">=</span> tree.<span style="color: #ded492;">export_graphviz</span>(
    clf, <span style="color: #9CDCFE;">out_file</span><span style="color: #e0e0e0;">=</span><span style="color: #569CD6;">None</span>,
    <span style="color: #9CDCFE;">feature_names</span><span style="color: #e0e0e0;">=</span>iris.<span style="color: #9CDCFE;">feature_names</span>,
    <span style="color: #9CDCFE;">class_names</span><span style="color: #e0e0e0;">=</span>iris.<span style="color: #9CDCFE;">target_names</span>,
    <span style="color: #9CDCFE;">filled</span><span style="color: #e0e0e0;">=</span><span style="color: #569CD6;">True</span>, <span style="color: #9CDCFE;">rounded</span><span style="color: #e0e0e0;">=</span><span style="color: #569CD6;">True</span>,
    <span style="color: #9CDCFE;">special_characters</span><span style="color: #e0e0e0;">=</span><span style="color: #569CD6;">True</span>
)
<span style="color: #9CDCFE;">graph</span> <span style="color: #e0e0e0;">=</span> pydotplus.<span style="color: #ded492;">graph_from_dot_data</span>(dot_data)
graph.<span style="color: #ded492;">write_png</span>(file)
<span style="color: #C586C0;">print</span>(file)
</pre>
</div>

<div class="org" id="orgfea793b">

<div id="org06b93e7" class="figure">
<p><img src="./../resources/tree1.png" alt="tree1.png" width="500px" />
</p>
</div>

</div>

<p>
In this case the first node will use the petal length, if it is less than 2.45, then it will classify the entry as setosa. Because the <code>gini</code> is 0.0, we only have a single category in this node, so the node doesn&rsquo;t have any children or other possible categories. However, in the other node, we have a <code>gini</code> of 0.5, meaning we have two categories with the same weight.
</p>

<p>
If we stop at the second node, all the remaining observations are classified as, in this case, versicolor. However, we keep splitting the tree into more nodes until we find nodes where there was only one class left, <code>gini</code> is 0.0, these nodes are known as leaves as there are no more branches available.
</p>

<p>
If we decide to cut the three at some point in the middle and keep the top part, we are left with the more relevant and less granular features at the bottom.
</p>
</div>
</div>

<div id="outline-container-aggregation" class="outline-3">
<h3 id="aggregation"><span class="section-number-3">8.2.</span> Aggregation</h3>
<div class="outline-text-3" id="text-aggregation">
<p>
Anomalies in the training dataset can trick these trees, so we need to use Aggregation to deal with this. It takes a lot of simple algorithms and then takes a consensus, so instead of having a large tree we will have several small trees (weak classifiers) and we put them together to build a strong classifier which we can trust.
</p>

<p>
We generate an algorithm that decides how to take into consideration the prediction of all single algorithms, such a majority vote (the most voted class wins), or techniques that use the Sensitivity for weighting the results of the vote.
</p>
</div>
</div>
</div>

<div id="outline-container-random-forest-by-hand" class="outline-2">
<h2 id="random-forest-by-hand"><span class="section-number-2">9.</span> Random Forest by Hand</h2>
<div class="outline-text-2" id="text-random-forest-by-hand">
</div>

<div id="outline-container-org5666fc5" class="outline-3">
<h3 id="org5666fc5"><span class="section-number-3">9.1.</span> Imports</h3>
<div class="outline-text-3" id="text-9-1">
<div class="src-name" id="org7a5886b">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> matplotlib </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> pyplot </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> plt</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.datasets </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> make_classification</span>
<span style="color: #569CD6;">import</span> <span style="color: #4EC9B0;">numpy </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> np</span>
<span style="color: #569CD6;">import</span> <span style="color: #4EC9B0;">pandas </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> pd</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.model_selection </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> train_test_split</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.preprocessing </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">StandardScaler</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.metrics </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> classification_report</span>

<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.tree </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">DecisionTreeClassifier</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.metrics </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> accuracy_score, confusion_matrix</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.utils.random </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> sample_without_replacement</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.utils </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> resample</span>
</pre>
</div>

<pre class="example" id="orgf2823c8">

</pre>
</div>
</div>

<div id="outline-container-create-data" class="outline-3">
<h3 id="create-data"><span class="section-number-3">9.2.</span> Create Data</h3>
<div class="outline-text-3" id="text-create-data">
<p>
We will create a dataset with <code>make_classification</code> (like blobs but multi-dimensional), this will help us test our model. In this case we will set it to have 1000 samples, with 10 features from which 5 are useful.
</p>

<p>
Then we create the <code>DataFrame</code> and <code>split</code> the data into test and train. We will standarize the data (mean is 0, std is 1) and normalize the numeric values using the <code>StandardScaler</code>. Then we use this model to transform the train and test sets.
</p>

<div class="src-name" id="org3f717a5">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">X</span>, <span style="color: #9CDCFE;">y</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">make_classification</span>(<span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">42</span>, <span style="color: #9CDCFE;">n_features</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">10</span>, <span style="color: #9CDCFE;">n_informative</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">5</span>, <span style="color: #9CDCFE;">n_redundant</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">0</span>, <span style="color: #9CDCFE;">n_samples</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1000</span>)
<span style="color: #9CDCFE;">X</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">pd</span>.<span style="color: #4EC9B0;">DataFrame</span>(<span style="color: #e0e0e0;">X</span>)
<span style="color: #9CDCFE;">X_train</span>, <span style="color: #9CDCFE;">X_test</span>, <span style="color: #9CDCFE;">y_train</span>, <span style="color: #9CDCFE;">y_test</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">train_test_split</span>(<span style="color: #e0e0e0;">X</span>, y, <span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>)
<span style="color: #9CDCFE;">scaler</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">StandardScaler</span>().<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_train</span>)
<span style="color: #9CDCFE;">X_train_scaled</span> <span style="color: #e0e0e0;">=</span> scaler.<span style="color: #ded492;">transform</span>(<span style="color: #4EC9B0;">X_train</span>)
<span style="color: #9CDCFE;">X_test_scaled</span> <span style="color: #e0e0e0;">=</span> scaler.<span style="color: #ded492;">transform</span>(<span style="color: #4EC9B0;">X_test</span>)
<span style="color: #C586C0;">print</span>(<span style="color: #4EC9B0;">X_test_scaled</span>.<span style="color: #9CDCFE;">shape</span>)
</pre>
</div>

<pre class="example" id="org6a4be87">
(250, 10)
</pre>
</div>
</div>

<div id="outline-container-predict" class="outline-3">
<h3 id="predict"><span class="section-number-3">9.3.</span> Predict</h3>
<div class="outline-text-3" id="text-predict">
<p>
We will do model, fit predict in one step and get a the confusion matrix out of our prediction. Then we print the classification report.
</p>

<div class="src-name" id="org9f59265">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">clf</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">DecisionTreeClassifier</span>().<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_train_scaled</span>, y_train)
<span style="color: #9CDCFE;">y_pred</span> <span style="color: #e0e0e0;">=</span> clf.<span style="color: #ded492;">predict</span>(<span style="color: #4EC9B0;">X_test_scaled</span>)
<span style="color: #9CDCFE;">cm</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">confusion_matrix</span>(y_test, y_pred)
<span style="color: #9CDCFE;">cm_df</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">pd</span>.<span style="color: #4EC9B0;">DataFrame</span>(
    cm.<span style="color: #ded492;">reshape</span>(<span style="color: #BBCCAA;">2</span>, <span style="color: #BBCCAA;">2</span>), <span style="color: #9CDCFE;">index</span><span style="color: #e0e0e0;">=</span>[<span style="color: #CE9178;">"Actual 0"</span>, <span style="color: #CE9178;">"Actual 1"</span>],
    <span style="color: #9CDCFE;">columns</span><span style="color: #e0e0e0;">=</span>[<span style="color: #CE9178;">"Predicted 0"</span>, <span style="color: #CE9178;">"Predicted 1"</span>]
)
<span style="color: #C586C0;">print</span>(cm_df)
</pre>
</div>

<pre class="example" id="orgf0845b1">
          Predicted 0  Predicted 1
Actual 0          109           20
Actual 1            9          112
</pre>

<p>
We will note that the testing score is not great as trees are not great at generalizing.
</p>

<div class="src-name" id="org3fa6adc">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #C586C0;">print</span>(<span style="color: #ded492;">classification_report</span>(y_test, y_pred))
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"Training Score:"</span>, clf.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_train_scaled</span>, y_train))
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"Testing Score:"</span>, clf.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_test_scaled</span>, y_test))
</pre>
</div>

<pre class="example" id="org0058e98">
              precision    recall  f1-score   support

           0       0.92      0.84      0.88       129
           1       0.85      0.93      0.89       121

    accuracy                           0.88       250
   macro avg       0.89      0.89      0.88       250
weighted avg       0.89      0.88      0.88       250

Training Score: 1.0
Testing Score: 0.884
</pre>
</div>
</div>

<div id="outline-container-bagging" class="outline-3">
<h3 id="bagging"><span class="section-number-3">9.4.</span> Bagging</h3>
<div class="outline-text-3" id="text-bagging">
<p>
Bagging allows us to give different samples to different trees so that the aggregation of all trees have seen all our dataset together but not individually.
</p>

<p>
Instead of using a single tree, we will build many programmatically and try to take the best decision possible for each. In this case we will also visualize the score of each tree.
</p>

<div class="src-name" id="orgab98e49">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">file</span> <span style="color: #e0e0e0;">=</span> <span style="color: #CE9178;">"../resources/bagging1.png"</span>
<span style="color: #9CDCFE;">clfs</span> <span style="color: #e0e0e0;">=</span> []
<span style="color: #9CDCFE;">scores</span> <span style="color: #e0e0e0;">=</span> []

<span style="color: #569CD6;">for</span> <span style="color: #9CDCFE;">i</span> <span style="color: #569CD6;">in</span> <span style="color: #C586C0;">range</span>(<span style="color: #BBCCAA;">50</span>):
    <span style="color: #9CDCFE;">X_train_scaled_bootstrap</span>, <span style="color: #9CDCFE;">y_train_bootstrap</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">resample</span>(<span style="color: #4EC9B0;">X_train_scaled</span>, y_train, <span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span>i)

    <span style="color: #9CDCFE;">clf</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">DecisionTreeClassifier</span>(<span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span>i<span style="color: #e0e0e0;">+</span><span style="color: #BBCCAA;">200</span>).<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_train_scaled_bootstrap</span>, y_train_bootstrap)
    clfs.<span style="color: #ded492;">append</span>(clf)

    <span style="color: #9CDCFE;">y_preds</span> <span style="color: #e0e0e0;">=</span> [clf.<span style="color: #ded492;">predict</span>(<span style="color: #4EC9B0;">X_test_scaled</span>) <span style="color: #569CD6;">for</span> <span style="color: #9CDCFE;">clf</span> <span style="color: #569CD6;">in</span> clfs]
    <span style="color: #9CDCFE;">y_pred</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">pd</span>.<span style="color: #4EC9B0;">DataFrame</span>(y_preds).<span style="color: #ded492;">median</span>().<span style="color: #ded492;">round</span>()
    <span style="color: #9CDCFE;">score</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">accuracy_score</span>(y_test, y_pred)
    scores.<span style="color: #ded492;">append</span>(score)

<span style="color: #9CDCFE;">fig</span>, <span style="color: #9CDCFE;">ax</span> <span style="color: #e0e0e0;">=</span> plt.<span style="color: #ded492;">subplots</span>(<span style="color: #9CDCFE;">figsize</span><span style="color: #e0e0e0;">=</span>(<span style="color: #BBCCAA;">5</span>, <span style="color: #BBCCAA;">4</span>))
ax.<span style="color: #ded492;">set_title</span>(<span style="color: #CE9178;">"Scores"</span>)
ax.<span style="color: #ded492;">plot</span>(scores)
fig.<span style="color: #ded492;">savefig</span>(file)
<span style="color: #C586C0;">print</span>(file)
</pre>
</div>

<div class="org" id="orge898328">

<div id="orgc7e886e" class="figure">
<p><img src="../resources/bagging1.png" alt="bagging1.png" />
</p>
</div>

</div>
</div>
</div>

<div id="outline-container-random-forest-pre-built" class="outline-3">
<h3 id="random-forest-pre-built"><span class="section-number-3">9.5.</span> Random Forest Pre-built</h3>
<div class="outline-text-3" id="text-random-forest-pre-built">
<p>
We can instead use a pre-built Random Forest Classifier.
</p>

<div class="src-name" id="org12ed322">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.ensemble </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">RandomForestClassifier</span>

<span style="color: #9CDCFE;">clf</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">RandomForestClassifier</span>(<span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>, <span style="color: #9CDCFE;">n_estimators</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">50</span>).<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_train_scaled</span>, y_train)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"Previous Score by hand"</span>, <span style="color: #4EC9B0;">np</span>.<span style="color: #ded492;">mean</span>(scores))
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"Score Pre-built"</span>, clf.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_test_scaled</span>, y_test))
</pre>
</div>

<pre class="example" id="org1f3a48e">
Previous Score by hand 0.8984800000000003
Score Pre-built 0.904
</pre>

<p>
There are other Random Trees Algorithms.
</p>

<div class="src-name" id="org980bf0b">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.ensemble </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">ExtraTreesClassifier</span>

<span style="color: #9CDCFE;">clf</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">ExtraTreesClassifier</span>(<span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>, <span style="color: #9CDCFE;">n_estimators</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">50</span>).<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_train_scaled</span>, y_train)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"Train Score:"</span>, clf.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_train_scaled</span>, y_train))
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"Test Score:"</span>, clf.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_test_scaled</span>, y_test))
</pre>
</div>

<pre class="example" id="org51cc9f6">
Train Score: 1.0
Test Score: 0.928
</pre>
</div>
</div>

<div id="outline-container-ada-boost-classifier" class="outline-3">
<h3 id="ada-boost-classifier"><span class="section-number-3">9.6.</span> Ada-Boost Classifier</h3>
<div class="outline-text-3" id="text-ada-boost-classifier">
<p>
In AdaBoost, a model is trained then evaluated. After evaluating the errors of the first model, another model is trained. This time, however, the model gives extra weight to the errors from the previous model, so the subsequent models minimize similar errors. This process is repeated until the error rate is minimized.
</p>

<div class="src-name" id="org48cb14d">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.ensemble </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">AdaBoostClassifier</span>

<span style="color: #9CDCFE;">clf</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">AdaBoostClassifier</span>(<span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>, <span style="color: #9CDCFE;">n_estimators</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">50</span>, <span style="color: #9CDCFE;">base_estimator</span><span style="color: #e0e0e0;">=</span><span style="color: #4EC9B0;">DecisionTreeClassifier</span>(<span style="color: #9CDCFE;">max_depth</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">2</span>)).<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_train_scaled</span>, y_train)

<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"Train Score:"</span>, clf.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_train_scaled</span>, y_train))
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"Test Score:"</span>, clf.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_test_scaled</span>, y_test))
</pre>
</div>

<pre class="example" id="org098d4a2">

</pre>
</div>
</div>
</div>

<div id="outline-container-choosing-an-ensemble-model" class="outline-2">
<h2 id="choosing-an-ensemble-model"><span class="section-number-2">10.</span> Choosing an Ensemble Model</h2>
<div class="outline-text-2" id="text-choosing-an-ensemble-model">
</div>

<div id="outline-container-org545301d" class="outline-3">
<h3 id="org545301d"><span class="section-number-3">10.1.</span> Imports</h3>
<div class="outline-text-3" id="text-10-1">
<div class="src-name" id="org53799e5">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> matplotlib </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> pyplot </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> plt</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.datasets </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> make_regression</span>
<span style="color: #569CD6;">import</span> <span style="color: #4EC9B0;">numpy </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> np</span>
<span style="color: #569CD6;">import</span> <span style="color: #4EC9B0;">pandas </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> pd</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.model_selection </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> train_test_split</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.preprocessing </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">StandardScaler</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.metrics </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> classification_report</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-loading-the-data" class="outline-3">
<h3 id="loading-the-data"><span class="section-number-3">10.2.</span> Loading the Data</h3>
<div class="outline-text-3" id="text-loading-the-data">
<div class="src-name" id="orgbf8f6a6">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">df</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">pd</span>.<span style="color: #ded492;">read_csv</span>(<span style="color: #CE9178;">'../resources/diabetes.csv'</span>)
<span style="color: #9CDCFE;">X</span> <span style="color: #e0e0e0;">=</span> df.<span style="color: #ded492;">drop</span>(<span style="color: #CE9178;">'Outcome'</span>, <span style="color: #9CDCFE;">axis</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>)
<span style="color: #9CDCFE;">y</span> <span style="color: #e0e0e0;">=</span> df[<span style="color: #CE9178;">'Outcome'</span>]
<span style="color: #9CDCFE;">target_names</span> <span style="color: #e0e0e0;">=</span> [<span style="color: #CE9178;">"negative"</span>, <span style="color: #CE9178;">"positive"</span>]
<span style="color: #C586C0;">print</span>(df.<span style="color: #ded492;">head</span>())
</pre>
</div>

<pre class="example" id="org59eb085">
   Pregnancies  Glucose  ...  Age  Outcome
0            6      148  ...   50        1
1            1       85  ...   31        0
2            8      183  ...   32        1
3            1       89  ...   21        0
4            0      137  ...   33        1

[5 rows x 9 columns]
</pre>
</div>
</div>

<div id="outline-container-creating-a-tester-function" class="outline-3">
<h3 id="creating-a-tester-function"><span class="section-number-3">10.3.</span> Creating a Tester function</h3>
<div class="outline-text-3" id="text-creating-a-tester-function">
<p>
We can create a function to automate the process of testing each model.
</p>

<div class="src-name" id="org846c75c">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">def</span> <span style="color: #ded492;">model_tester</span>(<span style="color: #9CDCFE;">model</span>, <span style="color: #9CDCFE;">X</span>, <span style="color: #9CDCFE;">y</span>):
    <span style="color: #CE9178;">"""</span><span style="color: #CE9178;">Returns the classification report and the train and test scores of a given model</span><span style="color: #CE9178;">"""</span>
    <span style="color: #9CDCFE;">X_train</span>, <span style="color: #9CDCFE;">X_test</span>, <span style="color: #9CDCFE;">y_train</span>, <span style="color: #9CDCFE;">y_test</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">train_test_split</span>(<span style="color: #e0e0e0;">X</span>, y, <span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>)
    <span style="color: #9CDCFE;">scaler</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">StandardScaler</span>().<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_train</span>)
    <span style="color: #9CDCFE;">X_train_scaled</span> <span style="color: #e0e0e0;">=</span> scaler.<span style="color: #ded492;">transform</span>(<span style="color: #4EC9B0;">X_train</span>)
    <span style="color: #9CDCFE;">X_test_scaled</span> <span style="color: #e0e0e0;">=</span> scaler.<span style="color: #ded492;">transform</span>(<span style="color: #4EC9B0;">X_test</span>)
    <span style="color: #9CDCFE;">clf</span> <span style="color: #e0e0e0;">=</span> model.<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_train_scaled</span>, y_train)
    <span style="color: #9CDCFE;">y_pred</span> <span style="color: #e0e0e0;">=</span> model.<span style="color: #ded492;">predict</span>(<span style="color: #4EC9B0;">X_test_scaled</span>)
    <span style="color: #569CD6;">return</span> (
        <span style="color: #ded492;">classification_report</span>(y_test, y_pred, <span style="color: #9CDCFE;">target_names</span><span style="color: #e0e0e0;">=</span>target_names),
        clf.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_train_scaled</span>, y_train),
        clf.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_test_scaled</span>, y_test)
    )
<span style="color: #C586C0;">print</span>(model_tester)
</pre>
</div>

<pre class="example" id="org5c701a3">
&lt;function model_tester at 0x12ff17c20&gt;
</pre>
</div>
</div>

<div id="outline-container-using-the-function-to-compare-models" class="outline-3">
<h3 id="using-the-function-to-compare-models"><span class="section-number-3">10.4.</span> Using the function to compare models</h3>
<div class="outline-text-3" id="text-using-the-function-to-compare-models">
<div class="src-name" id="org469137d">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.ensemble </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">AdaBoostClassifier</span>

<span style="color: #9CDCFE;">report</span>, <span style="color: #9CDCFE;">train_score</span>, <span style="color: #9CDCFE;">test_score</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">model_tester</span>(<span style="color: #4EC9B0;">AdaBoostClassifier</span>(<span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>), <span style="color: #e0e0e0;">X</span>, y)
<span style="color: #C586C0;">print</span>(report, train_score, test_score)
</pre>
</div>

<pre class="example" id="org64f1e21">
              precision    recall  f1-score   support

    negative       0.83      0.85      0.84       123
    positive       0.73      0.70      0.71        69

    accuracy                           0.80       192
   macro avg       0.78      0.77      0.78       192
weighted avg       0.80      0.80      0.80       192
 0.8229166666666666 0.796875
</pre>

<div class="src-name" id="org4a850e7">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.ensemble </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">RandomForestClassifier</span>

<span style="color: #9CDCFE;">report</span>, <span style="color: #9CDCFE;">train_score</span>, <span style="color: #9CDCFE;">test_score</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">model_tester</span>(<span style="color: #4EC9B0;">RandomForestClassifier</span>(<span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>), <span style="color: #e0e0e0;">X</span>, y)
<span style="color: #C586C0;">print</span>(report, train_score, test_score)
</pre>
</div>

<pre class="example" id="org1fc7bc1">
              precision    recall  f1-score   support

    negative       0.83      0.89      0.86       123
    positive       0.78      0.67      0.72        69

    accuracy                           0.81       192
   macro avg       0.80      0.78      0.79       192
weighted avg       0.81      0.81      0.81       192
 1.0 0.8125
</pre>

<div class="src-name" id="org44218dd">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.ensemble </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">ExtraTreesClassifier</span>

<span style="color: #9CDCFE;">report</span>, <span style="color: #9CDCFE;">train_score</span>, <span style="color: #9CDCFE;">test_score</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">model_tester</span>(<span style="color: #4EC9B0;">ExtraTreesClassifier</span>(<span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>), <span style="color: #e0e0e0;">X</span>, y)
<span style="color: #C586C0;">print</span>(report, train_score, test_score)
</pre>
</div>

<pre class="example" id="orgc615cc3">
              precision    recall  f1-score   support

    negative       0.82      0.86      0.84       123
    positive       0.73      0.65      0.69        69

    accuracy                           0.79       192
   macro avg       0.77      0.76      0.76       192
weighted avg       0.78      0.79      0.78       192
 1.0 0.7864583333333334
</pre>
</div>
</div>
</div>

<div id="outline-container-feature-selection-with-random-forest" class="outline-2">
<h2 id="feature-selection-with-random-forest"><span class="section-number-2">11.</span> Feature Selection with Random Forest</h2>
<div class="outline-text-2" id="text-feature-selection-with-random-forest">
<p>
What feature selection allows us to do is to determine which features are useful to the model, giving out information about the target variable. We select a subset of features because this allows us to make our dataset smaller (reducing the width) and the models will lose complexity.
</p>

<p>
We can use the Random Forest models to try to select the best feature at every split. We can grab the complete Random Forest and see which features where used where, so we can get an idea of the importance of them. A feature is important if it appears in most trees and if it appears towards the top of the tree or if it is not a leaf.
</p>
</div>

<div id="outline-container-org44bd283" class="outline-3">
<h3 id="org44bd283"><span class="section-number-3">11.1.</span> Imports</h3>
<div class="outline-text-3" id="text-11-1">
<div class="src-name" id="org44cf786">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> matplotlib </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> pyplot </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> plt</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.datasets </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> make_classification</span>
<span style="color: #569CD6;">import</span> <span style="color: #4EC9B0;">numpy </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> np</span>
<span style="color: #569CD6;">import</span> <span style="color: #4EC9B0;">pandas </span><span style="color: #569CD6;">as</span><span style="color: #4EC9B0;"> pd</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.ensemble </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">RandomForestClassifier</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.linear_model </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">LogisticRegression</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.model_selection </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> train_test_split</span>
<span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.preprocessing </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">StandardScaler</span>
</pre>
</div>

<pre class="example" id="org186e0b0">

</pre>
</div>
</div>

<div id="outline-container-load-data" class="outline-3">
<h3 id="load-data"><span class="section-number-3">11.2.</span> Load Data</h3>
<div class="outline-text-3" id="text-load-data">
<div class="src-name" id="orga2b1e4f">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">df</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">pd</span>.<span style="color: #ded492;">read_csv</span>(<span style="color: #CE9178;">'../resources/arrhythmia.csv'</span>)
<span style="color: #569CD6;">for</span> <span style="color: #9CDCFE;">col</span> <span style="color: #569CD6;">in</span> df.<span style="color: #9CDCFE;">columns</span>:
    <span style="color: #569CD6;">if</span> df[col].<span style="color: #9CDCFE;">dtype</span> <span style="color: #e0e0e0;">==</span> <span style="color: #CE9178;">'object'</span>:
        df[<span style="color: #9CDCFE;">col</span>] <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">pd</span>.<span style="color: #ded492;">to_numeric</span>(df[col], <span style="color: #9CDCFE;">errors</span><span style="color: #e0e0e0;">=</span><span style="color: #CE9178;">'coerce'</span>)

df.<span style="color: #ded492;">drop</span>(<span style="color: #CE9178;">'J_angle'</span>, <span style="color: #9CDCFE;">axis</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>, <span style="color: #9CDCFE;">inplace</span><span style="color: #e0e0e0;">=</span><span style="color: #569CD6;">True</span>)
df.<span style="color: #ded492;">dropna</span>(<span style="color: #9CDCFE;">inplace</span><span style="color: #e0e0e0;">=</span><span style="color: #569CD6;">True</span>)

<span style="color: #9CDCFE;">X</span> <span style="color: #e0e0e0;">=</span> df.<span style="color: #ded492;">drop</span>(<span style="color: #CE9178;">'class'</span>, <span style="color: #9CDCFE;">axis</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>)
<span style="color: #9CDCFE;">y</span> <span style="color: #e0e0e0;">=</span> df[<span style="color: #CE9178;">'class'</span>] <span style="color: #e0e0e0;">!=</span> <span style="color: #BBCCAA;">1</span>
<span style="color: #C586C0;">print</span>(<span style="color: #e0e0e0;">X</span>.<span style="color: #9CDCFE;">shape</span>, y.<span style="color: #9CDCFE;">shape</span>)
</pre>
</div>

<pre class="example" id="org40fd508">
(420, 278) (420,)
</pre>
</div>
</div>

<div id="outline-container-split-the-data" class="outline-3">
<h3 id="split-the-data"><span class="section-number-3">11.3.</span> Split the Data</h3>
<div class="outline-text-3" id="text-split-the-data">
<div class="src-name" id="org3f5931b">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">X_train</span>, <span style="color: #9CDCFE;">X_test</span>, <span style="color: #9CDCFE;">y_train</span>, <span style="color: #9CDCFE;">y_test</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">train_test_split</span>(<span style="color: #e0e0e0;">X</span>, y, <span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>)
<span style="color: #9CDCFE;">scaler</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">StandardScaler</span>().<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_train</span>)
<span style="color: #9CDCFE;">X_train_scaled</span> <span style="color: #e0e0e0;">=</span> scaler.<span style="color: #ded492;">transform</span>(<span style="color: #4EC9B0;">X_train</span>)
<span style="color: #9CDCFE;">X_test_scaled</span> <span style="color: #e0e0e0;">=</span> scaler.<span style="color: #ded492;">transform</span>(<span style="color: #4EC9B0;">X_test</span>)

<span style="color: #C586C0;">print</span>(<span style="color: #4EC9B0;">X_train_scaled</span>.<span style="color: #9CDCFE;">shape</span>, <span style="color: #4EC9B0;">X_test_scaled</span>.<span style="color: #9CDCFE;">shape</span>)
</pre>
</div>

<pre class="example" id="org725a5d1">
(315, 278) (105, 278)
</pre>
</div>
</div>

<div id="outline-container-creating-a-first-model" class="outline-3">
<h3 id="creating-a-first-model"><span class="section-number-3">11.4.</span> Creating a first Model</h3>
<div class="outline-text-3" id="text-creating-a-first-model">
<p>
We are going to start by making a prediction with a Random Forest Classifier. Then later we may use another model as we will have less features.
</p>

<div class="src-name" id="org2ac6f43">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">clf</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">RandomForestClassifier</span>(<span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>, <span style="color: #9CDCFE;">n_estimators</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">500</span>).<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_train_scaled</span>, y_train)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"Scores (train, test):"</span>, clf.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_train_scaled</span>, y_train), clf.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_test_scaled</span>, y_test))
</pre>
</div>

<pre class="example" id="org12da6a6">
Scores (train, test): 1.0 0.7142857142857143
</pre>
</div>
</div>

<div id="outline-container-using-the-features-attribute" class="outline-3">
<h3 id="using-the-features-attribute"><span class="section-number-3">11.5.</span> Using the Features attribute</h3>
<div class="outline-text-3" id="text-using-the-features-attribute">
<p>
We can use the <code>feature_importances_</code> attribute of the Random Forest Model to get the importance of the features as an array.
</p>

<div class="src-name" id="org5e8e801">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">features</span> <span style="color: #e0e0e0;">=</span> clf.<span style="color: #9CDCFE;">feature_importances_</span>

<span style="color: #9CDCFE;">file</span> <span style="color: #e0e0e0;">=</span> <span style="color: #CE9178;">"../resources/features1.png"</span>
<span style="color: #9CDCFE;">fig</span>, <span style="color: #9CDCFE;">ax</span> <span style="color: #e0e0e0;">=</span> plt.<span style="color: #ded492;">subplots</span>(<span style="color: #9CDCFE;">figsize</span><span style="color: #e0e0e0;">=</span>(<span style="color: #BBCCAA;">5</span>, <span style="color: #BBCCAA;">3</span>))
ax.<span style="color: #ded492;">bar</span>(<span style="color: #9CDCFE;">x</span><span style="color: #e0e0e0;">=</span><span style="color: #C586C0;">range</span>(<span style="color: #C586C0;">len</span>(features)), <span style="color: #9CDCFE;">height</span><span style="color: #e0e0e0;">=</span>features)
fig.<span style="color: #ded492;">savefig</span>(file)

<span style="color: #C586C0;">print</span>(file)
</pre>
</div>

<div class="org" id="org460cc50">

<div id="org24496bd" class="figure">
<p><img src="../resources/features1.png" alt="features1.png" />
</p>
</div>

</div>

<div class="src-name" id="org7483580">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">df_f</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">pd</span>.<span style="color: #4EC9B0;">Series</span>(
    features, <span style="color: #9CDCFE;">index</span><span style="color: #e0e0e0;">=</span><span style="color: #e0e0e0;">X</span>.<span style="color: #9CDCFE;">columns</span>
)
df_f.<span style="color: #ded492;">sort_values</span>(<span style="color: #9CDCFE;">inplace</span><span style="color: #e0e0e0;">=</span><span style="color: #569CD6;">True</span>, <span style="color: #9CDCFE;">ascending</span><span style="color: #e0e0e0;">=</span><span style="color: #569CD6;">False</span>)
<span style="color: #C586C0;">print</span>(df_f.<span style="color: #ded492;">head</span>(<span style="color: #BBCCAA;">10</span>))
</pre>
</div>

<pre class="example" id="orge6d2274">
Heart_rate              0.080918
V4_QRSTA                0.043120
V1_QRSA                 0.033950
V5_R_wave_amplitude     0.030973
DII_T_wave_amplitude    0.027136
V3_JJ_wave_amplitude    0.023354
V2_JJ_wave_amplitude    0.022617
V6_T_wave_amplitude     0.022361
DII_R_wave_width        0.021570
AVF_Q_wave_amplitude    0.021205
dtype: float64
</pre>
</div>
</div>

<div id="outline-container-selecting-features" class="outline-3">
<h3 id="selecting-features"><span class="section-number-3">11.6.</span> Selecting Features</h3>
<div class="outline-text-3" id="text-selecting-features">
<p>
We don&rsquo;t need all the features so we will use the <code>feature_selection</code> module to get ony a few.
</p>

<p>
The support will be a description of which features are relevant based on the SelectModel fit.
</p>

<div class="src-name" id="orgc1be2d5">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #569CD6;">from</span><span style="color: #4EC9B0;"> sklearn.feature_selection </span><span style="color: #569CD6;">import</span><span style="color: #4EC9B0;"> </span><span style="color: #4EC9B0;">SelectFromModel</span>

<span style="color: #9CDCFE;">sel</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">SelectFromModel</span>(clf)
sel.<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_train_scaled</span>, y_train)
<span style="color: #9CDCFE;">supp</span> <span style="color: #e0e0e0;">=</span> sel.<span style="color: #ded492;">get_support</span>()
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"Support: "</span>, supp[:<span style="color: #BBCCAA;">20</span>])
</pre>
</div>

<pre class="example" id="org45f01c1">
Support:  [ True False  True  True  True False  True  True  True False False False
 False  True False False  True False False False]
</pre>
</div>
</div>

<div id="outline-container-new-model-with-the-selected-features" class="outline-3">
<h3 id="new-model-with-the-selected-features"><span class="section-number-3">11.7.</span> New Model with the Selected Features</h3>
<div class="outline-text-3" id="text-new-model-with-the-selected-features">
<p>
We will re-train the model but using <code>sel.transform</code> on our dataset to select only the features we are interested in (those who make the cut).
</p>

<div class="src-name" id="orgaaced9a">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">X_selected_train</span>, <span style="color: #9CDCFE;">X_selected_test</span>, <span style="color: #9CDCFE;">y_train</span>, <span style="color: #9CDCFE;">y_test</span> <span style="color: #e0e0e0;">=</span> <span style="color: #ded492;">train_test_split</span>(sel.<span style="color: #ded492;">transform</span>(<span style="color: #e0e0e0;">X</span>), y, <span style="color: #9CDCFE;">random_state</span><span style="color: #e0e0e0;">=</span><span style="color: #BBCCAA;">1</span>)
<span style="color: #9CDCFE;">scaler</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">StandardScaler</span>().<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_selected_train</span>)
<span style="color: #9CDCFE;">X_selected_train_scaled</span> <span style="color: #e0e0e0;">=</span> scaler.<span style="color: #ded492;">transform</span>(<span style="color: #4EC9B0;">X_selected_train</span>)
<span style="color: #9CDCFE;">X_selected_test_scaled</span> <span style="color: #e0e0e0;">=</span> scaler.<span style="color: #ded492;">transform</span>(<span style="color: #4EC9B0;">X_selected_test</span>)
<span style="color: #C586C0;">print</span>(<span style="color: #4EC9B0;">X_selected_train_scaled</span>.<span style="color: #9CDCFE;">shape</span>, <span style="color: #4EC9B0;">X_selected_test_scaled</span>.<span style="color: #9CDCFE;">shape</span>)
</pre>
</div>

<pre class="example" id="org25f61e3">
/Users/albertovaldez/.pyenv/versions/3.7.13/lib/python3.7/site-packages/sklearn/base.py:444: UserWarning: X has feature names, but SelectFromModel was fitted without feature names
  f"X has feature names, but {self.__class__.__name__} was fitted without"
(315, 108) (105, 108)
</pre>
</div>
</div>

<div id="outline-container-evaluating-the-new-model" class="outline-3">
<h3 id="evaluating-the-new-model"><span class="section-number-3">11.8.</span> Evaluating the new Model</h3>
<div class="outline-text-3" id="text-evaluating-the-new-model">
<div class="src-name" id="org4013867">
<p>

</p>

</div>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #9CDCFE;">clf</span> <span style="color: #e0e0e0;">=</span> <span style="color: #4EC9B0;">LogisticRegression</span>().<span style="color: #ded492;">fit</span>(<span style="color: #4EC9B0;">X_train_scaled</span>, y_train)
<span style="color: #C586C0;">print</span>(<span style="color: #CE9178;">"Scored (train, test):"</span>, clf.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_train_scaled</span>, y_train), clf.<span style="color: #ded492;">score</span>(<span style="color: #4EC9B0;">X_test_scaled</span>, y_test))
</pre>
</div>

<pre class="example" id="org8aade5d">
Scored (train, test): 0.9523809523809523 0.7142857142857143
</pre>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Alberto Valdez</p>
<p class="date">Created: 2022-11-03 Thu 17:46</p>
</div>
</body>
</html>
